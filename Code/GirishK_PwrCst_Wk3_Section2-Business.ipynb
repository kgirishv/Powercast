{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9685b81e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-22T22:40:24.569097Z",
     "iopub.status.busy": "2025-08-22T22:40:24.568485Z",
     "iopub.status.idle": "2025-08-22T22:41:47.840525Z",
     "shell.execute_reply": "2025-08-22T22:41:47.839859Z",
     "shell.execute_reply.started": "2025-08-22T22:40:24.569057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile: dev\n",
      "MLflow available: False\n",
      "Results dir: /home/6376f5a9-d12b-4255-9426-c0091ad440a7/Powercast/results/Wk03_Section2_dev\n",
      "Section report path: /home/6376f5a9-d12b-4255-9426-c0091ad440a7/Powercast/results/Wk03_Section2_dev/reports/SDS-CP036-powercast_Wk03_Section2_Business_Report.md\n",
      "Consolidated report path: /home/6376f5a9-d12b-4255-9426-c0091ad440a7/Powercast/SDS-CP036-powercast_Wk03_Report_Business.md\n",
      "Done upserting Section 2.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Week 3 - Section 2: MLflow Experiment Tracking (Business)\n",
    "# Single Code Cell Execution — with Profiles: dev, preprod, final\n",
    "# Includes: Upsert into consolidated Week 3 report (no duplicates).\n",
    "\n",
    "import os, re, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def upsert_section_in_consolidated(consolidated_path: Path, section_text: str,\n",
    "                                   header_variants: list[str],\n",
    "                                   insert_order_hint: list[str] | None = None):\n",
    "    \"\"\"\n",
    "    Replace the block that starts with any header in `header_variants`.\n",
    "    If none exists, append (or insert before the first hint header, if provided).\n",
    "    Robust to '-' vs '–' and avoids inline regex flags collisions.\n",
    "    \"\"\"\n",
    "    consolidated_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    existing = consolidated_path.read_text(encoding=\"utf-8\") if consolidated_path.exists() else \"\"\n",
    "    text = existing.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    # Build regex to remove any existing block for this section\n",
    "    hdr_alt = \"|\".join(re.escape(h) for h in header_variants)\n",
    "    any_sds_hdr = r\"^\\#\\s*SDS-CP036-powercast\\s*[–-]\\s*Week\\s*3\\s*Section\\s*\\d+:\\s*.*$\"\n",
    "    block_pat = rf\"^(?:{hdr_alt})\\s*.*?(?=^{any_sds_hdr}|\\Z)\"\n",
    "    text = re.sub(block_pat, \"\", text, flags=re.M | re.S).strip()\n",
    "\n",
    "    # Prepare the new (clean) block to insert\n",
    "    new_block = section_text.strip()\n",
    "\n",
    "    def insert_before_first_hint(container: str, block: str, hints: list[str]) -> str:\n",
    "        for h in hints:\n",
    "            m = re.search(rf\"^{re.escape(h)}\\s*$\", container, flags=re.M)\n",
    "            if m:\n",
    "                return container[:m.start()] + (block + \"\\n\\n---\\n\\n\") + container[m.start():]\n",
    "        return container + (\"\\n\\n---\\n\\n\" if container.strip() else \"\") + block\n",
    "\n",
    "    if insert_order_hint:\n",
    "        text = insert_before_first_hint(text, new_block, insert_order_hint)\n",
    "    else:\n",
    "        text = text + (\"\\n\\n---\\n\\n\" if text.strip() else \"\") + new_block\n",
    "\n",
    "    consolidated_path.write_text(text.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# ---------- Optional model deps (graceful fallback) ----------\n",
    "XGB_AVAILABLE = True\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "except Exception:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "SARIMAX_AVAILABLE = True\n",
    "try:\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "except Exception:\n",
    "    SARIMAX_AVAILABLE = False\n",
    "\n",
    "MLFLOW_AVAILABLE = True\n",
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "except Exception:\n",
    "    MLFLOW_AVAILABLE = False\n",
    "\n",
    "# ---------- Project paths & helpers ----------\n",
    "BASE_PROJECT_NAME = \"SDS-CP036-powercast\"\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    cur = start\n",
    "    for _ in range(12):\n",
    "        if (cur / \"data\").exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    return start  # fallback\n",
    "\n",
    "BASE_DIR = find_repo_root(Path.cwd())\n",
    "\n",
    "# ---------- Profiles (dev, preprod, final) ----------\n",
    "PROFILE = \"dev\"  # choose: \"dev\", \"preprod\", \"final\"\n",
    "\n",
    "profiles = {\n",
    "    \"dev\":     dict(FAST_MODE=True,  RESAMPLE_TO=\"H\", MAX_DAYS=365,\n",
    "                    TEST_DAYS=7,  BACKTEST=False, BACKTEST_FOLDS=0, BACKTEST_STEP_DAYS=0, BACKTEST_HOURS=0),\n",
    "    \"preprod\": dict(FAST_MODE=False, RESAMPLE_TO=\"H\", MAX_DAYS=365,\n",
    "                    TEST_DAYS=28, BACKTEST=False, BACKTEST_FOLDS=0, BACKTEST_STEP_DAYS=0, BACKTEST_HOURS=0),\n",
    "    \"final\":   dict(FAST_MODE=False, RESAMPLE_TO=\"H\", MAX_DAYS=365,\n",
    "                    TEST_DAYS=None, BACKTEST=True, BACKTEST_FOLDS=6, BACKTEST_STEP_DAYS=7, BACKTEST_HOURS=168),\n",
    "}\n",
    "cfg = profiles[PROFILE]\n",
    "\n",
    "FAST_MODE   = cfg[\"FAST_MODE\"]\n",
    "RESAMPLE_TO = cfg[\"RESAMPLE_TO\"]\n",
    "MAX_DAYS    = cfg[\"MAX_DAYS\"]\n",
    "TEST_DAYS   = cfg[\"TEST_DAYS\"]\n",
    "BACKTEST    = cfg[\"BACKTEST\"]\n",
    "BACKTEST_FOLDS = cfg[\"BACKTEST_FOLDS\"]\n",
    "BACKTEST_STEP_DAYS = cfg[\"BACKTEST_STEP_DAYS\"]\n",
    "BACKTEST_HOURS = cfg[\"BACKTEST_HOURS\"]\n",
    "\n",
    "# Results per profile (keeps outputs separate)\n",
    "RESULTS_DIR = BASE_DIR / \"results\" / f\"Wk03_Section2_{PROFILE}\"\n",
    "PLOTS_DIR   = RESULTS_DIR / \"plots\"\n",
    "REPORTS_DIR = RESULTS_DIR / \"reports\"\n",
    "for d in [RESULTS_DIR, PLOTS_DIR, REPORTS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- MLflow config ----------\n",
    "EXPERIMENT_NAME = \"powercast_wk03_s2\"\n",
    "LOCAL_MLRUNS = BASE_DIR / \"mlruns\"  # file-based tracking inside repo\n",
    "\n",
    "if MLFLOW_AVAILABLE:\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(f\"file://{LOCAL_MLRUNS.as_posix()}\")\n",
    "        mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] MLflow setup skipped:\", e)\n",
    "        MLFLOW_AVAILABLE = False\n",
    "\n",
    "# ---------- Load & prepare data ----------\n",
    "data_path = BASE_DIR / \"data\" / \"Tetuan City power consumption.csv\"\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found at: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "# Normalize column names (strip & collapse spaces like 'Zone 2  Power ...')\n",
    "df.columns = df.columns.str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "# Parse time & set index\n",
    "df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "df = df.set_index(\"DateTime\").sort_index()\n",
    "\n",
    "# Keep numeric cols only for modeling safety\n",
    "num_df = df.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "# Downsample & cap horizon\n",
    "if RESAMPLE_TO:\n",
    "    num_df = num_df.resample(RESAMPLE_TO).mean()\n",
    "if isinstance(MAX_DAYS, (int, float)):\n",
    "    try:\n",
    "        num_df = num_df.last(f\"{int(MAX_DAYS)}D\")\n",
    "    except Exception:\n",
    "        num_df = num_df.iloc[-24*int(MAX_DAYS):]\n",
    "\n",
    "zones = [\"Zone 1 Power Consumption\", \"Zone 2 Power Consumption\", \"Zone 3 Power Consumption\"]\n",
    "zones = [z for z in zones if z in num_df.columns]\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def mape_safe(y_true, y_pred):\n",
    "    denom = np.where(y_true == 0, np.nan, np.abs(y_true))\n",
    "    return float(np.nanmean(np.abs(y_true - y_pred) / denom) * 100.0)\n",
    "\n",
    "def evaluate_forecast(y_true, y_pred):\n",
    "    return {\n",
    "        \"RMSE\": float(mean_squared_error(y_true, y_pred, squared=False)),\n",
    "        \"MAE\": float(mean_absolute_error(y_true, y_pred)),\n",
    "        \"MAPE\": mape_safe(np.asarray(y_true), np.asarray(y_pred)),\n",
    "    }\n",
    "\n",
    "def plot_and_save(zone, y_true_index, y_true, y_pred, model_name):\n",
    "    plt.figure(figsize=(11,4))\n",
    "    plt.plot(y_true_index, y_true, label=\"Actual\")\n",
    "    plt.plot(y_true_index, y_pred, label=f\"Predicted ({model_name})\")\n",
    "    plt.title(f\"{zone} - {model_name}\")\n",
    "    plt.legend()\n",
    "    safe_zone = re.sub(r\"[^A-Za-z0-9_.-]+\",\"_\", zone)\n",
    "    safe_model = re.sub(r\"[^A-Za-z0-9_.-]+\",\"_\", model_name)\n",
    "    fname = PLOTS_DIR / f\"{safe_zone}_{safe_model}.png\"\n",
    "    plt.savefig(fname, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return fname\n",
    "\n",
    "def log_run_mlflow(zone, model_name, params, metrics, artifacts_paths):\n",
    "    if not MLFLOW_AVAILABLE:\n",
    "        return None\n",
    "    with mlflow.start_run(run_name=f\"{PROFILE}__{zone}__{model_name}\"):\n",
    "        mlflow.log_params({\n",
    "            \"profile\": PROFILE,\n",
    "            \"zone\": zone,\n",
    "            \"resample\": RESAMPLE_TO,\n",
    "            \"max_days\": MAX_DAYS,\n",
    "            \"fast_mode\": FAST_MODE,\n",
    "            **params,\n",
    "        })\n",
    "        mlflow.log_metrics(metrics)\n",
    "        for p in artifacts_paths:\n",
    "            try:\n",
    "                mlflow.log_artifact(str(p))\n",
    "            except Exception as e:\n",
    "                print(\"[WARN] Could not log artifact\", p, \":\", e)\n",
    "        mlflow.set_tag(\"section\", \"Wk03_Section2\")\n",
    "        return mlflow.active_run().info.run_id\n",
    "\n",
    "def rolling_splits(index, folds=4, step_days=7, horizon_hours=168):\n",
    "    step = pd.Timedelta(days=step_days)\n",
    "    horizon = pd.Timedelta(hours=horizon_hours)\n",
    "    end = index.max()\n",
    "    splits = []\n",
    "    cur_test_end = end\n",
    "    for fold in range(folds):\n",
    "        test_start = cur_test_end - horizon + pd.Timedelta(hours=1)\n",
    "        val_end = test_start - pd.Timedelta(hours=1)\n",
    "        val_start = val_end - step + pd.Timedelta(hours=1)\n",
    "        train_end = val_start - pd.Timedelta(hours=1)\n",
    "        if train_end <= index.min():\n",
    "            break\n",
    "        tr_mask = (index <= train_end)\n",
    "        va_mask = (index >= val_start) & (index <= val_end)\n",
    "        te_mask = (index >= test_start) & (index <= cur_test_end)\n",
    "        splits.append((tr_mask, va_mask, te_mask))\n",
    "        cur_test_end = test_start - pd.Timedelta(hours=1)\n",
    "    return splits\n",
    "\n",
    "# ---------- Experiment execution ----------\n",
    "summary_rows = []\n",
    "\n",
    "try:\n",
    "    if not BACKTEST:\n",
    "        # Single hold-out mode\n",
    "        if TEST_DAYS is None:\n",
    "            TEST_DAYS = 7\n",
    "        test = num_df.last(f\"{TEST_DAYS}D\")\n",
    "        pre = num_df.iloc[: -len(test)] if len(num_df) > len(test) else num_df.iloc[:0]\n",
    "        n_pre = len(pre)\n",
    "        n_train = int(n_pre * 0.85)  # 85% train, 15% val\n",
    "        train = pre.iloc[:n_train]\n",
    "        val = pre.iloc[n_train:]\n",
    "\n",
    "        # Baseline (Naive)\n",
    "        for zone in zones:\n",
    "            if len(val) == 0 or len(test) == 0:\n",
    "                continue\n",
    "            y_true = test[zone].values\n",
    "            pivot = val[zone].iloc[-1] if len(val) else train[zone].iloc[-1]\n",
    "            y_pred = np.repeat(pivot, len(test))\n",
    "            metrics = evaluate_forecast(y_true, y_pred)\n",
    "            plot_file = plot_and_save(zone, test.index, y_true, y_pred, \"Baseline (Naive)\")\n",
    "            run_id = log_run_mlflow(zone, \"Baseline (Naive)\", {\"model\": \"baseline\"}, metrics, [plot_file])\n",
    "            summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"Baseline (Naive)\", **metrics, \"Fold\": None, \"mlflow_run_id\": run_id})\n",
    "\n",
    "        # SARIMAX (light)\n",
    "        if SARIMAX_AVAILABLE:\n",
    "            for zone in zones:\n",
    "                try:\n",
    "                    if len(train) < 10 or len(test) == 0:\n",
    "                        continue\n",
    "                    model = SARIMAX(train[zone], order=(1,1,1), seasonal_order=(0,1,1,24),\n",
    "                                    enforce_stationarity=False, enforce_invertibility=False)\n",
    "                    res = model.fit(disp=False)\n",
    "                    fc = res.get_forecast(steps=len(test)).predicted_mean\n",
    "                    y_pred = fc.values\n",
    "                    y_true = test[zone].values\n",
    "                    metrics = evaluate_forecast(y_true, y_pred)\n",
    "                    plot_file = plot_and_save(zone, test.index, y_true, y_pred, \"SARIMAX(1,1,1)(0,1,1,24)\")\n",
    "                    run_id = log_run_mlflow(zone, \"SARIMAX(1,1,1)(0,1,1,24)\",\n",
    "                                            {\"model\": \"sarimax\", \"order\": \"(1,1,1)\", \"seasonal_order\": \"(0,1,1,24)\"},\n",
    "                                            metrics, [plot_file])\n",
    "                    summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"SARIMAX(1,1,1)(0,1,1,24)\", **metrics, \"Fold\": None, \"mlflow_run_id\": run_id})\n",
    "                except Exception as e:\n",
    "                    summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"SARIMAX\", \"RMSE\": np.nan, \"MAE\": np.nan, \"MAPE\": np.nan, \"Fold\": None, \"mlflow_run_id\": None})\n",
    "\n",
    "        # XGBoost with lag features (if available)\n",
    "        if XGB_AVAILABLE:\n",
    "            def make_lag_df(series, lags=24):\n",
    "                df_l = pd.DataFrame({\"y\": series})\n",
    "                for L in range(1, lags+1):\n",
    "                    df_l[f\"lag_{L}\"] = df_l[\"y\"].shift(L)\n",
    "                return df_l.dropna()\n",
    "\n",
    "            LAGS = 24\n",
    "            for zone in zones:\n",
    "                try:\n",
    "                    series = pd.concat([train[zone], val[zone], test[zone]])\n",
    "                    df_lag = make_lag_df(series, lags=LAGS)\n",
    "                    n_train_lag = len(train)\n",
    "                    n_val_lag = len(val)\n",
    "                    split_idx = n_train_lag + n_val_lag - LAGS\n",
    "                    train_ml = df_lag.iloc[:split_idx]\n",
    "                    test_ml = df_lag.iloc[split_idx:]\n",
    "                    X_tr, y_tr = train_ml.drop(columns=[\"y\"]), train_ml[\"y\"]\n",
    "                    X_te, y_te = test_ml.drop(columns=[\"y\"]), test_ml[\"y\"]\n",
    "                    model = XGBRegressor(\n",
    "                        n_estimators=120 if FAST_MODE else 200,\n",
    "                        max_depth=4 if FAST_MODE else 6,\n",
    "                        learning_rate=0.1,\n",
    "                        subsample=0.9,\n",
    "                        colsample_bytree=0.9,\n",
    "                        objective=\"reg:squarederror\",\n",
    "                        n_jobs=0\n",
    "                    )\n",
    "                    model.fit(X_tr, y_tr, verbose=False)\n",
    "                    y_pred = model.predict(X_te)\n",
    "                    y_true_idx = test.index[-len(y_pred):]\n",
    "                    y_true = test[zone].reindex(y_true_idx).values\n",
    "                    metrics = evaluate_forecast(y_true, y_pred)\n",
    "                    plot_file = plot_and_save(zone, y_true_idx, y_true, y_pred, \"XGBoost (lags)\")\n",
    "                    run_id = log_run_mlflow(zone, \"XGBoost (lags)\",\n",
    "                                            {\"model\": \"xgboost_lags\", \"lags\": LAGS, \"n_estimators\": int(model.get_params().get(\"n_estimators\", 0))},\n",
    "                                            metrics, [plot_file])\n",
    "                    summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"XGBoost (lags)\", **metrics, \"Fold\": None, \"mlflow_run_id\": run_id})\n",
    "                except Exception as e:\n",
    "                    summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"XGBoost (lags)\", \"RMSE\": np.nan, \"MAE\": np.nan, \"MAPE\": np.nan, \"Fold\": None, \"mlflow_run_id\": None})\n",
    "\n",
    "        results_df = pd.DataFrame(summary_rows)\n",
    "        results_csv = REPORTS_DIR / \"mlflow_run_summary.csv\"\n",
    "        results_df.to_csv(results_csv, index=False)\n",
    "\n",
    "    else:\n",
    "        # Rolling backtest mode\n",
    "        idx = num_df.index\n",
    "        splits = rolling_splits(idx, folds=BACKTEST_FOLDS, step_days=BACKTEST_STEP_DAYS, horizon_hours=BACKTEST_HOURS)\n",
    "\n",
    "        for zone in zones:\n",
    "            for fold_id, (tr_m, va_m, te_m) in enumerate(splits, start=1):\n",
    "                train = num_df.loc[tr_m]\n",
    "                val   = num_df.loc[va_m]\n",
    "                test  = num_df.loc[te_m]\n",
    "\n",
    "                # Baseline\n",
    "                try:\n",
    "                    y_true = test[zone].values\n",
    "                    pivot = val[zone].iloc[-1] if len(val) else train[zone].iloc[-1]\n",
    "                    y_pred = np.repeat(pivot, len(test))\n",
    "                    metrics = evaluate_forecast(y_true, y_pred)\n",
    "                    run_id = log_run_mlflow(zone, \"Baseline (Naive)\",\n",
    "                                            {\"model\": \"baseline\", \"fold\": fold_id, \"horizon_h\": BACKTEST_HOURS},\n",
    "                                            metrics, [])\n",
    "                    summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"Baseline (Naive)\", **metrics, \"Fold\": fold_id, \"mlflow_run_id\": run_id})\n",
    "                except Exception:\n",
    "                    summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"Baseline (Naive)\", \"RMSE\": np.nan, \"MAE\": np.nan, \"MAPE\": np.nan, \"Fold\": fold_id, \"mlflow_run_id\": None})\n",
    "\n",
    "                # SARIMAX\n",
    "                if SARIMAX_AVAILABLE:\n",
    "                    try:\n",
    "                        if len(train) > 10:\n",
    "                            model = SARIMAX(train[zone], order=(1,1,1),\n",
    "                                            seasonal_order=(0,1,1,24),\n",
    "                                            enforce_stationarity=False, enforce_invertibility=False)\n",
    "                            res = model.fit(disp=False)\n",
    "                            y_pred = res.get_forecast(steps=len(test)).predicted_mean.values\n",
    "                            metrics = evaluate_forecast(y_true, y_pred)\n",
    "                            run_id = log_run_mlflow(zone, \"SARIMAX(1,1,1)(0,1,1,24)\",\n",
    "                                                    {\"model\": \"sarimax\", \"order\": \"(1,1,1)\", \"seasonal_order\": \"(0,1,1,24)\",\n",
    "                                                     \"fold\": fold_id, \"horizon_h\": BACKTEST_HOURS},\n",
    "                                                    metrics, [])\n",
    "                            summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"SARIMAX(1,1,1)(0,1,1,24)\", **metrics, \"Fold\": fold_id, \"mlflow_run_id\": run_id})\n",
    "                    except Exception:\n",
    "                        summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"SARIMAX\", \"RMSE\": np.nan, \"MAE\": np.nan, \"MAPE\": np.nan, \"Fold\": fold_id, \"mlflow_run_id\": None})\n",
    "\n",
    "                # XGBoost (lags)\n",
    "                if XGB_AVAILABLE:\n",
    "                    try:\n",
    "                        def make_lag_df(series, lags=24):\n",
    "                            df_l = pd.DataFrame({\"y\": series})\n",
    "                            for L in range(1, lags+1):\n",
    "                                df_l[f\"lag_{L}\"] = df_l[\"y\"].shift(L)\n",
    "                            return df_l.dropna()\n",
    "\n",
    "                        LAGS = 24\n",
    "                        series = pd.concat([train[zone], val[zone], test[zone]])\n",
    "                        df_lag = make_lag_df(series, lags=LAGS)\n",
    "                        n_train_lag = len(train)\n",
    "                        n_val_lag = len(val)\n",
    "                        split_idx = n_train_lag + n_val_lag - LAGS\n",
    "                        train_ml = df_lag.iloc[:split_idx]\n",
    "                        test_ml = df_lag.iloc[split_idx:]\n",
    "                        X_tr, y_tr = train_ml.drop(columns=[\"y\"]), train_ml[\"y\"]\n",
    "                        X_te, y_te = test_ml.drop(columns=[\"y\"]), test_ml[\"y\"]\n",
    "\n",
    "                        model = XGBRegressor(\n",
    "                            n_estimators=150,\n",
    "                            max_depth=5,\n",
    "                            learning_rate=0.08 if not FAST_MODE else 0.1,\n",
    "                            subsample=0.9,\n",
    "                            colsample_bytree=0.9,\n",
    "                            objective=\"reg:squarederror\",\n",
    "                            n_jobs=0\n",
    "                        )\n",
    "                        model.fit(X_tr, y_tr, verbose=False)\n",
    "                        y_pred = model.predict(X_te)\n",
    "                        y_true_idx = test.index[-len(y_pred):]\n",
    "                        y_true = test[zone].reindex(y_true_idx).values\n",
    "                        metrics = evaluate_forecast(y_true, y_pred)\n",
    "                        run_id = log_run_mlflow(zone, \"XGBoost (lags)\",\n",
    "                                                {\"model\": \"xgboost_lags\", \"lags\": LAGS, \"n_estimators\": int(model.get_params().get(\"n_estimators\", 0)),\n",
    "                                                 \"fold\": fold_id, \"horizon_h\": BACKTEST_HOURS},\n",
    "                                                metrics, [])\n",
    "                        summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"XGBoost (lags)\", **metrics, \"Fold\": fold_id, \"mlflow_run_id\": run_id})\n",
    "                    except Exception:\n",
    "                        summary_rows.append({\"Profile\": PROFILE, \"Zone\": zone, \"Model\": \"XGBoost (lags)\", \"RMSE\": np.nan, \"MAE\": np.nan, \"MAPE\": np.nan, \"Fold\": fold_id, \"mlflow_run_id\": None})\n",
    "\n",
    "        # Save fold-level results + aggregates\n",
    "        results_df = pd.DataFrame(summary_rows)\n",
    "        results_csv = REPORTS_DIR / \"mlflow_run_summary_folds.csv\"\n",
    "        results_df.to_csv(results_csv, index=False)\n",
    "\n",
    "        agg = results_df.groupby([\"Zone\",\"Model\"]).agg(\n",
    "            RMSE_mean=(\"RMSE\",\"mean\"), RMSE_std=(\"RMSE\",\"std\"),\n",
    "            MAE_mean=(\"MAE\",\"mean\"),   MAE_std=(\"MAE\",\"std\"),\n",
    "            MAPE_mean=(\"MAPE\",\"mean\"), MAPE_std=(\"MAPE\",\"std\")\n",
    "        ).reset_index()\n",
    "        agg_csv = REPORTS_DIR / \"mlflow_aggregate_summary.csv\"\n",
    "        agg.to_csv(agg_csv, index=False)\n",
    "\n",
    "        champs = agg.sort_values([\"Zone\",\"RMSE_mean\"]).groupby(\"Zone\").head(1)\n",
    "        champs_csv = REPORTS_DIR / \"mlflow_champions.csv\"\n",
    "        champs.to_csv(champs_csv, index=False)\n",
    "\n",
    "finally:\n",
    "    # ---------- Build the Section Report (Core + ALWAYS Business Summary) ----------\n",
    "    section_report_path = REPORTS_DIR / \"SDS-CP036-powercast_Wk03_Section2_Business_Report.md\"\n",
    "    consolidated_report_path = BASE_DIR / \"SDS-CP036-powercast_Wk03_Report_Business.md\"\n",
    "\n",
    "    if not BACKTEST:\n",
    "        csv_link_line = \"[Run Summary - CSV](mlflow_run_summary.csv)\"\n",
    "        extra_lines = []\n",
    "    else:\n",
    "        csv_link_line = \"[Run Summary (folds) - CSV](mlflow_run_summary_folds.csv)\"\n",
    "        extra_lines = [\n",
    "            \"[Aggregate Summary - CSV](mlflow_aggregate_summary.csv)\",\n",
    "            \"[Champion Models - CSV](mlflow_champions.csv)\",\n",
    "        ]\n",
    "\n",
    "    core_md = [\n",
    "        f\"# {BASE_PROJECT_NAME} - Week 3 Section 2: MLflow Experiment Tracking\",\n",
    "        \"\",\n",
    "        f\"Profile: **{PROFILE}**\",\n",
    "        \"\",\n",
    "        \"## Key Questions Answered\",\n",
    "        \"\",\n",
    "        \"Q: Which evaluation metrics did you use to assess model performance, and why are they appropriate for this problem?\",\n",
    "        \"A: We used RMSE, MAE, and MAPE. RMSE penalizes large errors (useful for risk), MAE provides an easy-to-explain average miss, and MAPE gives a percentage error that business users understand.\",\n",
    "        \"\",\n",
    "        \"Q: How did you use MLflow to track your experiments and results?\",\n",
    "        f\"A: We created an MLflow experiment named {EXPERIMENT_NAME} and logged, for each run:\",\n",
    "        \"- Parameters: model name, resampling (hour/hourly), lags, seasonal order, profile tag, fast_mode flag.\",\n",
    "        \"- Metrics: RMSE, MAE, MAPE for the evaluation window.\",\n",
    "        \"- Artifacts: Actual vs Predicted plots per zone (in single hold-out), or per fold (in backtesting).\",\n",
    "        \"Tracking runs locally via a file-based MLflow backend keeps everything versioned inside the repo (mlruns/).\",\n",
    "        \"\",\n",
    "        \"Q: What insights did you gain from comparing actual vs. predicted curves for each zone?\",\n",
    "        \"A: Visual comparisons showed how models capture shape (daily patterns), timing (peaks/valleys), and magnitude (over/under-bias). These help pinpoint which model is most reliable for each zone's operations.\",\n",
    "        \"\",\n",
    "        csv_link_line,\n",
    "    ] + ([\"\"] + extra_lines if extra_lines else [])\n",
    "\n",
    "    business_md_always = [\n",
    "        \"---\",\n",
    "        \"\",\n",
    "        \"## Business Value Summary (Executive View)\",\n",
    "        \"- Transparency & Trust: Every experiment is versioned with parameters, metrics, and plots so leaders can see how conclusions were reached.\",\n",
    "        '- Faster Decisions: Side-by-side comparisons shorten the path to a \"champion\" model for each zone.',\n",
    "        \"- Risk Control: Using RMSE/MAE/MAPE together prevents over-optimizing for a single metric and missing real-world errors.\",\n",
    "        \"- Governance & Auditability: A local MLflow history (mlruns/) provides an auditable trail for compliance, board reviews, or customer assurances.\",\n",
    "        \"- Scalability: Profiles (dev/preprod/final) let us move from quick smoke-tests to robust selection without changing code.\",\n",
    "    ]\n",
    "\n",
    "    REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    with open(section_report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(core_md + [\"\"] + business_md_always))\n",
    "\n",
    "    # ===== Upsert into consolidated (replace-or-append) =====\n",
    "    SECTION1_HEADERS = [\n",
    "        \"# SDS-CP036-powercast - Week 3 Section 1: Model Selection & Training\",\n",
    "        \"# SDS-CP036-powercast – Week 3 Section 1: Model Selection & Training\",\n",
    "    ]\n",
    "    SECTION2_HEADERS = [\n",
    "        \"# SDS-CP036-powercast - Week 3 Section 2: MLflow Experiment Tracking\",\n",
    "        \"# SDS-CP036-powercast – Week 3 Section 2: MLflow Experiment Tracking\",\n",
    "    ]\n",
    "    section_text = Path(section_report_path).read_text(encoding=\"utf-8\")\n",
    "    upsert_section_in_consolidated(\n",
    "        consolidated_path=consolidated_report_path,\n",
    "        section_text=section_text,\n",
    "        header_variants=SECTION2_HEADERS,\n",
    "        insert_order_hint=SECTION1_HEADERS  # prefer after Section 1 if present\n",
    "    )\n",
    "\n",
    "    # Helpful debug info\n",
    "    print(\"Profile:\", PROFILE)\n",
    "    print(\"MLflow available:\", MLFLOW_AVAILABLE)\n",
    "    print(\"Results dir:\", RESULTS_DIR.resolve())\n",
    "    print(\"Section report path:\", section_report_path.resolve())\n",
    "    print(\"Consolidated report path:\", consolidated_report_path.resolve())\n",
    "    print(\"Done upserting Section 2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed552243-ca3f-4e13-ab8c-0268cb283815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
