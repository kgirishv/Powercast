{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "384a4712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T03:57:06.857982Z",
     "iopub.status.busy": "2025-08-15T03:57:06.857719Z",
     "iopub.status.idle": "2025-08-15T03:57:08.214711Z",
     "shell.execute_reply": "2025-08-15T03:57:08.214198Z",
     "shell.execute_reply.started": "2025-08-15T03:57:06.857961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Section 2 (Business, full) complete.\n",
      "- Report: /home/6376f5a9-d12b-4255-9426-c0091ad440a7/Powercast/results/Wk01_Section2/reports/SDS-CP036-powercast_Wk01_Section2_Report_Business.md\n",
      "- Plots: section2_daily_averages.png section2_box_by_dow.png section2_heatmap_zone1.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Week 1 â€“ Section 2: Temporal Trends (Business, full) =====\n",
    "from pathlib import Path\n",
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Shared Header / Naming ----------\n",
    "BASE_PROJECT_NAME = \"SDS-CP036-powercast\"\n",
    "WEEK = \"Wk01\"\n",
    "SECTION = \"Section2\"\n",
    "RUN_TAG = f\"{WEEK}_{SECTION}\"\n",
    "\n",
    "# Prefer running relative to this file; fall back to CWD when executed in notebooks\n",
    "BASE_DIR = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd().resolve()\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    \"\"\"Find a reasonable project root; if not found, use start.\"\"\"\n",
    "    cur = start\n",
    "    for _ in range(10):\n",
    "        if (cur / \".git\").exists() or (cur / \"data\").exists():\n",
    "            return cur\n",
    "        if cur.parent == cur:\n",
    "            break\n",
    "        cur = cur.parent\n",
    "    return start\n",
    "\n",
    "def _is_writable(dirpath: Path) -> bool:\n",
    "    try:\n",
    "        dirpath.mkdir(parents=True, exist_ok=True)\n",
    "        tmp = dirpath / \"__write_test__\"\n",
    "        tmp.write_text(\"ok\", encoding=\"utf-8\")\n",
    "        tmp.unlink(missing_ok=True)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "REPO_ROOT = find_repo_root(BASE_DIR)\n",
    "DATA_DIR  = REPO_ROOT / \"data\"\n",
    "OUTPUT_ROOT = REPO_ROOT if _is_writable(REPO_ROOT / \"results\") else BASE_DIR\n",
    "\n",
    "RESULTS_DIR  = OUTPUT_ROOT / \"results\" / RUN_TAG\n",
    "PLOTS_DIR    = RESULTS_DIR / \"plots\"\n",
    "REPORTS_DIR  = RESULTS_DIR / \"reports\"\n",
    "for d in (RESULTS_DIR, PLOTS_DIR, REPORTS_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BUSINESS_SUMMARY_MD  = REPORTS_DIR / f\"{BASE_PROJECT_NAME}_{RUN_TAG}_Report_Business.md\"\n",
    "\n",
    "# --- Locate energy CSV flexibly (Tetuan only, or ENV override) ---\n",
    "CANDIDATES = [\n",
    "    DATA_DIR / \"Tetuan City power consumption.csv\",\n",
    "    Path(\"/mnt/data/Tetuan City power consumption.csv\"),\n",
    "]\n",
    "env_path = os.environ.get(\"ENERGY_CSV_PATH\")\n",
    "if env_path:\n",
    "    CANDIDATES.insert(0, Path(env_path))\n",
    "\n",
    "ENERGY_CSV = next((p for p in CANDIDATES if p.exists()), None)\n",
    "if ENERGY_CSV is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not locate Tetuan dataset. Looked for:\\n  - \" + \"\\n  - \".join(map(str, CANDIDATES))\n",
    "    )\n",
    "\n",
    "# ---------- Loader (normalized headers + aliasing) ----------\n",
    "def _parse_datetime_series(series: pd.Series) -> pd.Series:\n",
    "    dt = pd.to_datetime(series, errors=\"coerce\")\n",
    "    if dt.isna().mean() > 0.5:\n",
    "        dt = pd.to_datetime(series, errors=\"coerce\", dayfirst=True)\n",
    "    return dt\n",
    "\n",
    "def normalize_and_alias(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 1) normalize headers (handles \"Zone 2  Power Consumption\" â†’ \"Zone 2 Power Consumption\")\n",
    "    df.columns = [re.sub(r\"\\s+\", \" \", c).strip() for c in df.columns]\n",
    "\n",
    "    # 2) build/use DateTime\n",
    "    if \"DateTime\" in df.columns:\n",
    "        df[\"DateTime\"] = _parse_datetime_series(df[\"DateTime\"].astype(str))\n",
    "    elif {\"Date\", \"Time\"}.issubset(df.columns):\n",
    "        df[\"DateTime\"] = _parse_datetime_series(df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str))\n",
    "    else:\n",
    "        raise ValueError(f\"Need 'DateTime' or 'Date'+'Time'. Got: {list(df.columns)}\")\n",
    "\n",
    "    # 3) alias Tetuan zone cols â†’ legacy names expected by downstream code\n",
    "    zone_map = {\n",
    "        \"Zone 1 Power Consumption\": \"Sub_metering_1\",\n",
    "        \"Zone 2 Power Consumption\": \"Sub_metering_2\",\n",
    "        \"Zone 3 Power Consumption\": \"Sub_metering_3\",\n",
    "    }\n",
    "    for src, dst in zone_map.items():\n",
    "        if src in df.columns and dst not in df.columns:\n",
    "            df.rename(columns={src: dst}, inplace=True)\n",
    "\n",
    "    # 4) validate required columns\n",
    "    required = [\"DateTime\", \"Sub_metering_1\", \"Sub_metering_2\", \"Sub_metering_3\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"Missing required columns after normalization/aliasing: {missing}\\n\"\n",
    "            f\"Available: {df.columns.tolist()}\"\n",
    "        )\n",
    "\n",
    "    # 5) final clean/sort\n",
    "    return df.dropna(subset=[\"DateTime\"]).sort_values(\"DateTime\").reset_index(drop=True)\n",
    "\n",
    "# --- Load & prepare ---\n",
    "df_raw = pd.read_csv(ENERGY_CSV, sep=\",\", low_memory=False)\n",
    "if len(df_raw.columns) == 1:\n",
    "    df_raw = pd.read_csv(ENERGY_CSV, sep=\";\", low_memory=False)\n",
    "df = normalize_and_alias(df_raw.copy())\n",
    "\n",
    "# --- Enrich time features ---\n",
    "df[\"Date\"] = df[\"DateTime\"].dt.date\n",
    "df[\"Hour\"] = df[\"DateTime\"].dt.hour\n",
    "df[\"DoW\"]  = df[\"DateTime\"].dt.dayofweek  # 0=Mon,6=Sun\n",
    "dow_names = [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\n",
    "df[\"DoW_Name\"] = df[\"DoW\"].map({i:n for i,n in enumerate(dow_names)})\n",
    "\n",
    "# --- Totals & aggregations ---\n",
    "df[\"Total_kW\"] = df[[\"Sub_metering_1\",\"Sub_metering_2\",\"Sub_metering_3\"]].astype(float).sum(axis=1)\n",
    "\n",
    "daily_avg = df.groupby(\"Date\")[[\"Sub_metering_1\",\"Sub_metering_2\",\"Sub_metering_3\",\"Total_kW\"]].mean()\n",
    "daily_avg.index = pd.to_datetime(daily_avg.index)\n",
    "\n",
    "dow_stats = df.groupby(\"DoW_Name\")[\"Total_kW\"].agg([\"mean\",\"median\",\"std\",\"count\"]).reindex(dow_names)\n",
    "hourly_zone1 = df.groupby(\"Hour\")[\"Sub_metering_1\"].mean()\n",
    "\n",
    "# --- Visualizations (matplotlib; one chart per figure, no explicit colors) ---\n",
    "# 1) Line plot: daily averages (Total + Zones)\n",
    "plt.figure()\n",
    "plt.plot(daily_avg.index, daily_avg[\"Total_kW\"], label=\"Total_kW\")\n",
    "plt.plot(daily_avg.index, daily_avg[\"Sub_metering_1\"], label=\"Zone1\")\n",
    "plt.plot(daily_avg.index, daily_avg[\"Sub_metering_2\"], label=\"Zone2\")\n",
    "plt.plot(daily_avg.index, daily_avg[\"Sub_metering_3\"], label=\"Zone3\")\n",
    "plt.title(\"Daily Averages: Total & Zones\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average kW\")\n",
    "plt.legend()\n",
    "line_path = PLOTS_DIR / \"section2_daily_averages.png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(line_path)\n",
    "plt.close()\n",
    "\n",
    "# 2) Box plot: Total_kW by day of week\n",
    "data_by_dow = [df.loc[df[\"DoW\"]==i, \"Total_kW\"].values for i in range(7) if (df[\"DoW\"]==i).any()]\n",
    "plt.figure()\n",
    "plt.boxplot(data_by_dow, labels=[dow_names[i] for i in range(len(data_by_dow))], showmeans=True)\n",
    "plt.title(\"Total Consumption by Day of Week\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"kW\")\n",
    "box_path = PLOTS_DIR / \"section2_box_by_dow.png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(box_path)\n",
    "plt.close()\n",
    "\n",
    "# 3) Heatmap: Zone 1 (Kitchen) Hour vs Day\n",
    "pivot_z1 = df.pivot_table(index=\"DoW\", columns=\"Hour\", values=\"Sub_metering_1\", aggfunc=\"mean\")\n",
    "pivot_z1 = pivot_z1.reindex(index=range(7))  # ensure order Mon..Sun\n",
    "plt.figure()\n",
    "plt.imshow(pivot_z1.values, aspect=\"auto\")\n",
    "plt.title(\"Zone 1 Avg kW â€” Hour vs Day-of-Week\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Day (0=Mon ... 6=Sun)\")\n",
    "plt.colorbar()\n",
    "heat_path = PLOTS_DIR / \"section2_heatmap_zone1.png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(heat_path)\n",
    "plt.close()\n",
    "\n",
    "# --- Business answers (data-driven) ---\n",
    "peak_dow = dow_stats[\"mean\"].idxmax() if not dow_stats[\"mean\"].isna().all() else \"NA\"\n",
    "peak_hour_z1 = int(hourly_zone1.idxmax()) if not hourly_zone1.empty else -1\n",
    "\n",
    "first_ts = str(df[\"DateTime\"].min())\n",
    "last_ts  = str(df[\"DateTime\"].max())\n",
    "\n",
    "# --- Business Report (Markdown) ---\n",
    "md = f\"\"\"# ðŸ’¼ Week 1 â€“ {SECTION}: Temporal Trends (Business-Friendly Report)\n",
    "\n",
    "## Dataset\n",
    "Using file: **{ENERGY_CSV.name}**  \n",
    "Period: **{first_ts} â†’ {last_ts}**  \n",
    "Rows: **{len(df):,}**\n",
    "\n",
    "## Key Questions Answered\n",
    "**Q1: What daily or weekly patterns are observable in power consumption across the three zones?**  \n",
    "- The **line plot** of daily averages (Total & Zones) shows overall movement and relative contribution by zone.  \n",
    "- By weekday, average total usage peaks on **{peak_dow}** based on the dataset's mean profile.\n",
    "\n",
    "**Q2: Are there seasonal or time-of-day peaks and dips in energy usage?**  \n",
    "- The **heatmap** for Zone 1 (kitchen proxy) highlights typical time-of-day peaks; the highest average hour is around **{peak_hour_z1}:00**.  \n",
    "- Broader seasonal effects can be explored by comparing monthly averages (extendable in this section if needed).\n",
    "\n",
    "**Q3: Which visualizations helped you uncover these patterns?**  \n",
    "- **Line plot** (daily averages): `plots/{line_path.name}`  \n",
    "- **Box plot** (by day of week): `plots/{box_path.name}`  \n",
    "- **Heatmap** (hour vs day for Zone 1): `plots/{heat_path.name}`\n",
    "\n",
    "## What we computed\n",
    "- Canonical **DateTime** and zone aliasing (**Zone 1/2/3 â†’ Sub_metering_1/2/3**).  \n",
    "- **Daily averages** of total and per-zone consumption.  \n",
    "- **Day-of-week distribution** (box plot) for total consumption.  \n",
    "- **Hour Ã— day heatmap** for Zone 1.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "BUSINESS_SUMMARY_MD.write_text(md, encoding=\"utf-8\")\n",
    "\n",
    "print(\"âœ… Section 2 (Business, full) complete.\")\n",
    "print(\"- Report:\", BUSINESS_SUMMARY_MD)\n",
    "print(\"- Plots:\", line_path.name, box_path.name, heat_path.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa289b92-a55b-4141-9be3-4fd95b401476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
