{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32caea93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T23:51:41.133402Z",
     "iopub.status.busy": "2025-08-15T23:51:41.133143Z",
     "iopub.status.idle": "2025-08-15T23:51:41.179391Z",
     "shell.execute_reply": "2025-08-15T23:51:41.178912Z",
     "shell.execute_reply.started": "2025-08-15T23:51:41.133384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Consolidation complete (inline plots v2) + README.md refreshed.\n",
      "Output consolidated: /home/6376f5a9-d12b-4255-9426-c0091ad440a7/Powercast/results/Wk01_CONSOLIDATED/SDS-CP036-powercast_Wk01_Business_Consolidated.md\n",
      "Updated README: /home/6376f5a9-d12b-4255-9426-c0091ad440a7/Powercast/README.md\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===== Week 1 – Consolidate Business Reports (Sections 1–5) — INLINE PLOTS v2\n",
    "# ===== Plus: write updated GitHub-style README.md (no other files) =====\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "BASE_PROJECT_NAME = \"SDS-CP036-powercast\"\n",
    "WEEK_TAG = \"Wk01\"\n",
    "SECTIONS = [1,2,3,4,5]\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    p = start.resolve()\n",
    "    for _ in range(12):\n",
    "        if (p / \"results\").exists() or (p / \"data\").exists():\n",
    "            return p\n",
    "        if p.parent == p: break\n",
    "        p = p.parent\n",
    "    return start.resolve()\n",
    "\n",
    "BASE_DIR = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd().resolve()\n",
    "PROJECT_ROOT = find_project_root(BASE_DIR)\n",
    "\n",
    "def section_dirs(sec: int):\n",
    "    sec_tag = f\"{WEEK_TAG}_Section{sec}\"\n",
    "    res_dir = PROJECT_ROOT / \"results\" / sec_tag\n",
    "    return res_dir, res_dir / \"reports\", res_dir / \"plots\"\n",
    "\n",
    "def expected_report_name(sec: int) -> str:\n",
    "    return f\"{BASE_PROJECT_NAME}_{WEEK_TAG}_Section{sec}_Report_Business.md\"\n",
    "\n",
    "def find_report_md(sec: int):\n",
    "    res_dir, rep_dir, _ = section_dirs(sec)\n",
    "    cand = rep_dir / expected_report_name(sec)\n",
    "    if cand.exists(): return cand\n",
    "    if rep_dir.exists():\n",
    "        any_md = sorted(rep_dir.glob(\"*Report_Business.md\"))\n",
    "        if any_md: return any_md[0]\n",
    "    if res_dir.exists():\n",
    "        any_md = sorted(res_dir.rglob(\"*Report_Business.md\"))\n",
    "        if any_md: return any_md[0]\n",
    "    return None\n",
    "\n",
    "def list_plot_files_for_section(sec: int):\n",
    "    \"\"\"Honor plot order mentioned in the MD whether referenced as `plots/...` or\n",
    "       `results/Wk01_SectionN/plots/...`. Then append remaining images from plots folder.\"\"\"\n",
    "    res_dir, rep_dir, plots_dir = section_dirs(sec)\n",
    "    md = find_report_md(sec)\n",
    "    ordered = []\n",
    "    seen = set()\n",
    "\n",
    "    def add_if_ok(p: Path):\n",
    "        if p.exists() and p.suffix.lower() in {\".png\", \".jpg\", \".jpeg\", \".webp\"}:\n",
    "            if p not in seen:\n",
    "                ordered.append(p); seen.add(p)\n",
    "\n",
    "    if md and md.exists():\n",
    "        text = md.read_text(encoding=\"utf-8\")\n",
    "        # 1) `plots/foo.png`\n",
    "        for m in re.finditer(r\"`plots/([^`]+)`\", text):\n",
    "            add_if_ok(plots_dir / m.group(1).strip())\n",
    "        # 2) ![](plots/foo.png)\n",
    "        for m in re.finditer(r\"!\\[[^\\]]*\\]\\(plots/([^)]+)\\)\", text):\n",
    "            add_if_ok(plots_dir / m.group(1).strip())\n",
    "        # 3) `results/Wk01_SectionN/plots/foo.png`\n",
    "        pat3 = rf\"`results/{WEEK_TAG}_Section{sec}/plots/([^`]+)`\"\n",
    "        for m in re.finditer(pat3, text):\n",
    "            add_if_ok(plots_dir / m.group(1).strip())\n",
    "        # 4) ![](results/Wk01_SectionN/plots/foo.png)\n",
    "        pat4 = rf\"!\\[[^\\]]*\\]\\(results/{WEEK_TAG}_Section{sec}/plots/([^)]+)\\)\"\n",
    "        for m in re.finditer(pat4, text):\n",
    "            add_if_ok(plots_dir / m.group(1).strip())\n",
    "\n",
    "    if plots_dir.exists():\n",
    "        for p in sorted(plots_dir.glob(\"*\")):\n",
    "            add_if_ok(p)\n",
    "\n",
    "    return ordered\n",
    "\n",
    "# --- Consolidation ---\n",
    "CONSOL_DIR = PROJECT_ROOT / \"results\" / f\"{WEEK_TAG}_CONSOLIDATED\"\n",
    "CONSOL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_MD = CONSOL_DIR / f\"{BASE_PROJECT_NAME}_{WEEK_TAG}_Business_Consolidated.md\"\n",
    "\n",
    "def make_toc(items):\n",
    "    lines = [\"## Table of Contents\"]\n",
    "    for sec, path, title in items:\n",
    "        lines.append(f\"- [Section {sec} — {title}](#section-{sec})\")\n",
    "    return \"\\n\".join(lines) + \"\\n\\n\"\n",
    "\n",
    "def extract_title(md_text: str, default: str):\n",
    "    m = re.search(r\"^#\\s+(.+)$\", md_text, flags=re.MULTILINE)\n",
    "    return m.group(1).strip() if m else default\n",
    "\n",
    "found = []\n",
    "missing = []\n",
    "for sec in SECTIONS:\n",
    "    p = find_report_md(sec)\n",
    "    if p is None:\n",
    "        missing.append(sec); continue\n",
    "    txt = p.read_text(encoding=\"utf-8\")\n",
    "    title = extract_title(txt, f\"{WEEK_TAG} Section {sec}\")\n",
    "    found.append((sec, p, title))\n",
    "\n",
    "header = f\"\"\"# {BASE_PROJECT_NAME} — {WEEK_TAG} Consolidated Business Report (Inline Plots v2)\n",
    "\n",
    "Generated on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "Project root: `{PROJECT_ROOT}`\n",
    "\n",
    "Includes Sections: {', '.join(str(s) for s,_,_ in found) if found else 'None'}\n",
    "{\"Missing Sections: \" + \", \".join(map(str, missing)) if missing else \"\"}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "toc = make_toc(found)\n",
    "\n",
    "body_parts = []\n",
    "for sec, path, title in found:\n",
    "    res_dir, rep_dir, plots_dir = section_dirs(sec)\n",
    "    section_anchor = f\"## Section {sec} — {title}\\n\"\n",
    "    txt = path.read_text(encoding=\"utf-8\")\n",
    "    # Strip the first H1 to avoid nested H1s\n",
    "    txt_no_h1 = re.sub(r\"^#\\s+.*\\n\", \"\", txt, count=1, flags=re.MULTILINE)\n",
    "    # Normalize any backticked or inline image 'plots/...' to project-relative\n",
    "    txt_no_h1 = re.sub(r\"`plots/([^`]+)`\",\n",
    "                       lambda m: f\"`results/{WEEK_TAG}_Section{sec}/plots/{m.group(1)}`\",\n",
    "                       txt_no_h1)\n",
    "    txt_no_h1 = re.sub(r\"!\\[([^\\]]*)\\]\\(plots/([^)]+)\\)\",\n",
    "                       lambda m: f\"![]({('results/' + f'{WEEK_TAG}_Section{sec}/plots/' + m.group(2))})\",\n",
    "                       txt_no_h1)\n",
    "\n",
    "    # --- Inline Visuals block ---\n",
    "    plot_files = list_plot_files_for_section(sec)\n",
    "    visuals_block_lines = [\"\\n### Visuals\\n\"]\n",
    "    if plot_files:\n",
    "        for p in plot_files:\n",
    "            rel = p.relative_to(PROJECT_ROOT).as_posix()\n",
    "            alt = f\"Section {sec} — {p.name}\"\n",
    "            visuals_block_lines.append(f\"![{alt}]({rel})\")\n",
    "    else:\n",
    "        visuals_block_lines.append(\"_No plot files found for this section._\")\n",
    "    visuals_block = \"\\n\".join(visuals_block_lines) + \"\\n\"\n",
    "\n",
    "    body_parts.append(section_anchor + \"\\n\" + txt_no_h1.strip() + \"\\n\" + visuals_block)\n",
    "\n",
    "OUT_MD.write_text(header + toc + \"\\n\".join(body_parts), encoding=\"utf-8\")\n",
    "\n",
    "# --- NEW: Write updated GitHub-style README.md (and only this extra file) ---\n",
    "def write_updated_readme(project_root: Path):\n",
    "    sections = SECTIONS\n",
    "    # Collect plots & reports\n",
    "    plots_by_sec = {}\n",
    "    reports_by_sec = {}\n",
    "    for s in sections:\n",
    "        res_dir, rep_dir, plots_dir = section_dirs(s)\n",
    "        # Plots\n",
    "        images = []\n",
    "        if plots_dir.exists():\n",
    "            for p in sorted(plots_dir.glob(\"*.*\")):\n",
    "                if p.suffix.lower() in {\".png\", \".jpg\", \".jpeg\", \".webp\"}:\n",
    "                    images.append(p)\n",
    "        plots_by_sec[s] = images\n",
    "        # Report\n",
    "        exp = rep_dir / expected_report_name(s)\n",
    "        if exp.exists():\n",
    "            reports_by_sec[s] = exp\n",
    "        else:\n",
    "            cands = sorted(rep_dir.glob(\"*Report_Business.md\")) if rep_dir.exists() else []\n",
    "            reports_by_sec[s] = cands[0] if cands else None\n",
    "\n",
    "    # README content per requested outline\n",
    "    def gallery_md():\n",
    "        lines = [\"## Quick Gallery (click any thumbnail)\"]\n",
    "        any_img = False\n",
    "        for s in sections:\n",
    "            imgs = plots_by_sec.get(s, [])[:2]\n",
    "            for img in imgs:\n",
    "                rel = img.relative_to(project_root).as_posix()\n",
    "                lines.append(f'<a href=\"./{rel}\"><img src=\"./{rel}\" width=\"260\" alt=\"Section {s} — {img.name}\"></a>')\n",
    "                any_img = True\n",
    "        if not any_img:\n",
    "            lines.append(\"_(No plots found yet — run Sections 1–5 scripts to generate them.)_\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def plots_grouped_md():\n",
    "        lines = [\"## Plots (grouped by Section)\"]\n",
    "        for s in sections:\n",
    "            lines.append(f\"### Wk01_Section{s}\")\n",
    "            imgs = plots_by_sec.get(s, [])\n",
    "            if not imgs:\n",
    "                lines.append(\"- _No plots found_\")\n",
    "            else:\n",
    "                for img in imgs:\n",
    "                    rel = img.relative_to(project_root).as_posix()\n",
    "                    lines.append(f\"- [{img.stem}](./{rel})\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    def reports_grouped_md():\n",
    "        lines = [\"## Section Reports (grouped)\"]\n",
    "        for s in sections:\n",
    "            lines.append(f\"### Wk01_Section{s}\")\n",
    "            rep = reports_by_sec.get(s)\n",
    "            if rep is None:\n",
    "                lines.append(\"- _No business report found_\")\n",
    "            else:\n",
    "                rel = rep.relative_to(project_root).as_posix()\n",
    "                txt = rep.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "                m = re.search(r\"^#\\s+(.+)$\", txt, flags=re.MULTILINE)\n",
    "                link_text = m.group(1) if m else rep.name\n",
    "                lines.append(f\"- [{link_text}](./{rel})\")\n",
    "        return \"\\n\".join(lines)\n",
    "\n",
    "    top_report = project_root / \"SDS-CP036-powercast_Wk01_Report_Business.md\"\n",
    "    top_link_line = f\"- [{top_report.name}](./{top_report.name})\"\n",
    "\n",
    "    readme_text = f\"\"\"# girish-kulkarni — Powercast (Beginner Track)\n",
    "\n",
    "**Team member:** [@kgirishv](https://github.com/kgirishv)\n",
    "\n",
    "> This folder contains my Week 1 business report and generated plots. Click any link below to open the image on GitHub.\n",
    "\n",
    "## Table of Contents\n",
    "- [Short Bio](#short-bio)\n",
    "- [How to Reproduce the Plots](#how-to-reproduce-the-plots)\n",
    "- [Quick Gallery (click any thumbnail)](#quick-gallery-click-any-thumbnail)\n",
    "- [Plots (grouped by Section)](#plots-grouped-by-section)\n",
    "- [Section Reports (grouped)](#section-reports-grouped)\n",
    "- [Top-level Week 1 Report](#top-level-week-1-report)\n",
    "\n",
    "## Short Bio\n",
    "Oracle SCM Cloud consultant and AI/ML practitioner. Building practical forecasting and analytics workflows for the Powercast project.\n",
    "\n",
    "## How to Reproduce the Plots\n",
    "- Clone my working repository with code/notebooks:  \n",
    "  `git clone https://github.com/kgirishv/Powercast.git`\n",
    "- Set up Python (3.10+) and install dependencies from `requirements.txt` in this folder.\n",
    "- Make sure data files are available (e.g., `Tetuan City power consumption.csv`).\n",
    "- Run the Week 1 notebooks/scripts as described in the Powercast repo.  \n",
    "  Rendered reports and figures are exported here under `results/` for easy review.\n",
    "\n",
    "{gallery_md()}\n",
    "\n",
    "{plots_grouped_md()}\n",
    "\n",
    "{reports_grouped_md()}\n",
    "\n",
    "## Top-level Week 1 Report\n",
    "{top_link_line}\n",
    "\n",
    "---\n",
    "_Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}_\n",
    "\"\"\"\n",
    "    (project_root / \"README.md\").write_text(readme_text.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# Write README now\n",
    "write_updated_readme(PROJECT_ROOT)\n",
    "\n",
    "print(\"✅ Consolidation complete (inline plots v2) + README.md refreshed.\")\n",
    "print(\"Output consolidated:\", OUT_MD)\n",
    "print(\"Updated README:\", PROJECT_ROOT / \"README.md\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b5fba-1e51-449b-a297-58614bb11e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86187157-bce6-41b6-a839-47043f5af2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
