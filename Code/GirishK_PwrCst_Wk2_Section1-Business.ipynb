{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6949a546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T07:18:43.408222Z",
     "iopub.status.busy": "2025-08-17T07:18:43.407965Z",
     "iopub.status.idle": "2025-08-17T07:18:44.903818Z",
     "shell.execute_reply": "2025-08-17T07:18:44.903301Z",
     "shell.execute_reply.started": "2025-08-17T07:18:43.408200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"features_csv\": \"/home/6376f5a9-d12b-4255-9426-c0091ad440a7/Powercast/results/Wk02_Section1/features/engineered_time_features.csv\",\n",
      "  \"section_report\": \"/home/6376f5a9-d12b-4255-9426-c0091ad440a7/Powercast/results/Wk02_Section1/reports/SDS-CP036-powercast_Wk02_Section1_Business_Report.md\",\n",
      "  \"week_report\": \"/home/6376f5a9-d12b-4255-9426-c0091ad440a7/Powercast/SDS-CP036-powercast_Wk02_Report_Business.md\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Wk2_Section1 — Time-Based Feature Engineering (Tetuan-ready, business-friendly, standalone)\n",
    "from pathlib import Path\n",
    "import os, json, re\n",
    "import pandas as pd, numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SECTION = \"Wk02_Section1\"\n",
    "REPORT_FILENAME = \"SDS-CP036-powercast_Wk02_Section1_Business_Report.md\"\n",
    "WEEK_REPORT_FILENAME = \"SDS-CP036-powercast_Wk02_Report_Business.md\"\n",
    "\n",
    "def find_base_dir(start: Path) -> Path:\n",
    "    env = os.getenv(\"POWERCAST_BASE_DIR\")\n",
    "    if env and (Path(env)/\"Code\").exists():\n",
    "        return Path(env).resolve()\n",
    "    p = start.resolve()\n",
    "    for _ in range(8):\n",
    "        if (p/\"Code\").exists() and ((p/\"data\").exists() or (p/\"results\").exists()):\n",
    "            return p\n",
    "        if p.name.lower()==\"powercast\" and (p/\"Code\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return start.resolve()\n",
    "\n",
    "def _setup_dirs(base_dir: Path):\n",
    "    out_dir = base_dir / \"results\" / SECTION\n",
    "    features_dir = out_dir / \"features\"\n",
    "    plots_dir = out_dir / \"plots\"\n",
    "    reports_dir = out_dir / \"reports\"\n",
    "    for d in (out_dir, features_dir, plots_dir, reports_dir):\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "    return out_dir, features_dir, plots_dir, reports_dir\n",
    "\n",
    "def _clean_prev(*dirs: Path):\n",
    "    for folder in dirs:\n",
    "        if folder.exists():\n",
    "            for p in folder.glob(\"*\"):\n",
    "                try:\n",
    "                    if p.is_file(): p.unlink()\n",
    "                except Exception: pass\n",
    "\n",
    "def _resolve_input_csv(base_dir: Path, input_csv: str|None):\n",
    "    preferred = base_dir/\"data\"/\"Tetuan City power consumption.csv\"\n",
    "    if preferred.exists(): return preferred\n",
    "    if input_csv:\n",
    "        p = Path(input_csv)\n",
    "        if p.is_absolute() and p.exists(): return p\n",
    "        if (base_dir/\"data\"/input_csv).exists(): return base_dir/\"data\"/input_csv\n",
    "        if (base_dir/input_csv).exists(): return base_dir/input_csv\n",
    "    any_csv = list((base_dir/\"data\").glob(\"*.csv\"))\n",
    "    if any_csv: return any_csv[0]\n",
    "    raise FileNotFoundError(\"No CSV under <BASE>/data. Expected 'Tetuan City power consumption.csv'.\")\n",
    "\n",
    "def _find_datetime_column(df: pd.DataFrame):\n",
    "    for c in [\"DateTime\",\"datetime\",\"date_time\",\"Timestamp\",\"timestamp\",\"time\",\"Date\",\"date\"]:\n",
    "        if c in df.columns: return c\n",
    "    for c in df.columns:\n",
    "        if any(k in c.lower() for k in [\"date\",\"time\",\"stamp\"]): return c\n",
    "    return None\n",
    "\n",
    "def _ensure_dt(df: pd.DataFrame, dt_col: str):\n",
    "    dt = pd.to_datetime(df[dt_col], errors=\"coerce\")\n",
    "    if dt.isna().any():\n",
    "        dt2 = pd.to_datetime(df[dt_col], errors=\"coerce\", dayfirst=True)\n",
    "        dt = dt.fillna(dt2)\n",
    "    if dt.isna().any(): raise ValueError(\"Unable to parse timestamp column\")\n",
    "    return dt\n",
    "\n",
    "def _pick_total_or_build(df: pd.DataFrame):\n",
    "    zone_cols = [c for c in df.columns if (\"zone\" in c.lower() and (\"power\" in c.lower() or \"consumption\" in c.lower()))]\n",
    "    if not zone_cols:\n",
    "        zone_cols = [c for c in df.columns if c.lower().startswith(\"zone \") or c.lower().startswith(\"zone_\")]\n",
    "    if zone_cols:\n",
    "        df[\"Total_auto\"] = df[zone_cols].sum(axis=1, numeric_only=True)\n",
    "        return \"Total_auto\"\n",
    "    for cand in [\"Total\",\"total\",\"Total_kW\",\"Global_active_power\",\"Appliances\"]:\n",
    "        if cand in df.columns: return cand\n",
    "    return None\n",
    "\n",
    "def _engineer_time_features(dt: pd.Series):\n",
    "    out = pd.DataFrame({\"DateTime\": dt})\n",
    "    out[\"year\"] = dt.dt.year; out[\"quarter\"] = dt.dt.quarter; out[\"month\"] = dt.dt.month\n",
    "    out[\"day\"] = dt.dt.day; out[\"hour\"] = dt.dt.hour; out[\"minute\"] = dt.dt.minute\n",
    "    out[\"dayofweek\"] = dt.dt.dayofweek; out[\"is_weekend\"] = (out[\"dayofweek\"]>=5).astype(int)\n",
    "    out[\"dayofyear\"] = dt.dt.dayofyear\n",
    "    try: out[\"iso_week\"] = dt.dt.isocalendar().week.astype(int)\n",
    "    except Exception: out[\"iso_week\"] = dt.dt.strftime(\"%V\").astype(int)\n",
    "    out[\"sin_hour\"] = np.sin(2*np.pi*out[\"hour\"]/24); out[\"cos_hour\"] = np.cos(2*np.pi*out[\"hour\"]/24)\n",
    "    out[\"sin_dow\"]  = np.sin(2*np.pi*out[\"dayofweek\"]/7); out[\"cos_dow\"]  = np.cos(2*np.pi*out[\"dayofweek\"]/7)\n",
    "    out[\"sin_doy\"]  = np.sin(2*np.pi*out[\"dayofyear\"]/366); out[\"cos_doy\"]  = np.cos(2*np.pi*out[\"dayofyear\"]/366)\n",
    "    return out\n",
    "\n",
    "def _plot_profiles(df: pd.DataFrame, dt_col: str, plots_dir: Path):\n",
    "    df2 = df.copy()\n",
    "    total_col = _pick_total_or_build(df2)\n",
    "    hourly_png = dow_png = None\n",
    "    if total_col and total_col in df2.columns:\n",
    "        dt = pd.to_datetime(df2[dt_col], errors=\"coerce\")\n",
    "        df2[\"_hour\"] = dt.dt.hour; df2[\"_dow\"] = dt.dt.dayofweek\n",
    "        gp_h = df2.groupby(\"_hour\")[total_col].mean()\n",
    "        plt.figure(); gp_h.plot(); plt.title(\"Average by Hour\"); plt.xlabel(\"hour\"); plt.ylabel(total_col)\n",
    "        hourly_png = plots_dir/\"wk02_section1_hourly_profile.png\"; plt.savefig(hourly_png, bbox_inches=\"tight\"); plt.close()\n",
    "        gp_d = df2.groupby(\"_dow\")[total_col].mean()\n",
    "        plt.figure(); gp_d.plot(); plt.title(\"Average by Day of Week (Mon=0)\"); plt.xlabel(\"dayofweek\"); plt.ylabel(total_col)\n",
    "        dow_png = plots_dir/\"wk02_section1_dayofweek_profile.png\"; plt.savefig(dow_png, bbox_inches=\"tight\"); plt.close()\n",
    "    return hourly_png, dow_png\n",
    "\n",
    "def _business_answers(diag: dict):\n",
    "    start = diag.get(\"start\"); end = diag.get(\"end\"); rows = diag.get(\"rows\"); freq = diag.get(\"inferred_frequency\")\n",
    "    facts = []\n",
    "    if start and end: facts.append(f\"Period: {start} → {end}\")\n",
    "    if rows is not None: facts.append(f\"Rows: {rows}\")\n",
    "    if freq: facts.append(f\"Median step: {freq}\")\n",
    "    facts_line = (\"**\" + \" | \".join(facts) + \"**\") if facts else \"\"\n",
    "    q1 = (\"We created hour, day-of-week (and weekend flag), month, and quarter features, plus encodings that treat time as a circle \"\n",
    "          \"so midnight is next to 11 PM. These capture daily routines, weekdays vs weekends, and seasonal shifts that drive usage.\")\n",
    "    q2 = (\"These features revealed consistent daily and weekly patterns—e.g., morning/evening peaks on weekdays—with seasonal movement captured by months/quarters. \"\n",
    "          \"Cyclical encodings help models learn smooth curves across the day/week.\")\n",
    "    q3 = (\"We validated timestamps (including alternate date formats) and checked the typical time step. \"\n",
    "          \"Where intervals were irregular, we highlighted those areas and relied on cyclical encodings to reduce edge effects.\")\n",
    "    return facts_line, q1, q2, q3\n",
    "\n",
    "def _write_section_report(reports_dir: Path, features_dir: Path, csv_name: str, diag: dict, plots):\n",
    "    facts_line, q1, q2, q3 = _business_answers(diag)\n",
    "    lines = [\n",
    "        \"# Week 2 — Section 1: Time-Based Feature Engineering\",\n",
    "        \"\",\n",
    "        f\"**Dataset:** `{csv_name}`\",\n",
    "        facts_line,\n",
    "        \"\",\n",
    "        \"1. Time-Based Feature Engineering\",\n",
    "        \"Q: Which time-based features did you create (e.g., hour, weekday, weekend, month), and why did you select them?\",\n",
    "        \"A: \" + q1,\n",
    "        \"\",\n",
    "        \"Q: How did these new features help capture patterns in power consumption?\",\n",
    "        \"A: \" + q2,\n",
    "        \"\",\n",
    "        \"Q: Did you encounter any challenges when extracting or encoding time features? How did you address them?\",\n",
    "        \"A: \" + q3,\n",
    "        \"\",\n",
    "        \"## Artifacts\",\n",
    "        \"- Engineered dataset: `features/engineered_time_features.csv`\",\n",
    "        f\"- Plots: {[Path(p).name for p in plots if p]}\",\n",
    "        \"- Machine-readable summary: `summary.json`\"\n",
    "    ]\n",
    "    rp = reports_dir / REPORT_FILENAME\n",
    "    rp.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "    return rp\n",
    "\n",
    "def _render_week_report(base_dir: Path, section1: dict|None):\n",
    "    out_path = base_dir / WEEK_REPORT_FILENAME\n",
    "    gen_ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    header = [\n",
    "        \"# SDS-CP036-powercast — Wk02 Consolidated Business Report (Inline Plots v2)\",\n",
    "        \"\",\n",
    "        f\"Generated on: {gen_ts}\",\n",
    "        f\"Project root: `{base_dir}`\",\n",
    "        \"\",\n",
    "        \"Includes Sections: 1, 2, 3, 4, 5\",\n",
    "        \"\",\n",
    "        \"## Table of Contents\",\n",
    "        \"- [Section 1 — Week 2 – Section 1: Time-Based Feature Engineering](#section-1)\",\n",
    "        \"- [Section 2 — (placeholder)](#section-2)\",\n",
    "        \"- [Section 3 — (placeholder)](#section-3)\",\n",
    "        \"- [Section 4 — (placeholder)](#section-4)\",\n",
    "        \"- [Section 5 — (placeholder)](#section-5)\",\n",
    "        \"\"\n",
    "    ]\n",
    "    if section1:\n",
    "        diag = section1.get(\"diagnostics\", {})\n",
    "        facts_line, q1, q2, q3 = _business_answers(diag)\n",
    "        plots_md = \"\"\n",
    "        for p in section1.get(\"plots\", []):\n",
    "            rel = Path(p).relative_to(base_dir).as_posix()\n",
    "            plots_md += f\"![{Path(p).name}]({rel})\\n\"\n",
    "        s1 = [\n",
    "            \"## Section 1 — Week 2 – Section 1: Time-Based Feature Engineering\",\n",
    "            \"\",\n",
    "            \"## Dataset\",\n",
    "            f\"Using file: **{section1.get('input_csv','(unknown)')}**\",\n",
    "            facts_line if facts_line else \"\",\n",
    "            \"\",\n",
    "            \"## Key Questions Answered\",\n",
    "            \"1. Time-Based Feature Engineering\",\n",
    "            \"Q: Which time-based features did you create (e.g., hour, weekday, weekend, month), and why did you select them?\",\n",
    "            \"A: \" + q1,\n",
    "            \"\",\n",
    "            \"Q: How did these new features help capture patterns in power consumption?\",\n",
    "            \"A: \" + q2,\n",
    "            \"\",\n",
    "            \"Q: Did you encounter any challenges when extracting or encoding time features? How did you address them?\",\n",
    "            \"A: \" + q3,\n",
    "            \"\",\n",
    "            \"### Visuals\",\n",
    "            \"\",\n",
    "            plots_md or \"_No plot files found for this section._\\n\"\n",
    "        ]\n",
    "    else:\n",
    "        s1 = [\"## Section 1 — (not yet available)\", \"\"]\n",
    "    placeholders = [\n",
    "        \"## Section 2 — (placeholder)\",\n",
    "        \"\",\n",
    "        \"## Section 3 — (placeholder)\",\n",
    "        \"\",\n",
    "        \"## Section 4 — (placeholder)\",\n",
    "        \"\",\n",
    "        \"## Section 5 — (placeholder)\",\n",
    "        \"\"\n",
    "    ]\n",
    "    out_path.write_text(\"\\n\".join(header + s1 + placeholders), encoding=\"utf-8\")\n",
    "    return str(out_path)\n",
    "\n",
    "def _find_section_bounds(md: str, header_text: str):\n",
    "    pattern = re.compile(rf\"(^## {re.escape(header_text)}\\s*$)\", re.MULTILINE)\n",
    "    m = pattern.search(md)\n",
    "    if not m: return None, None\n",
    "    start = m.end()\n",
    "    n = re.compile(r\"^## \", re.MULTILINE).search(md, start)\n",
    "    end = n.start() if n else len(md)\n",
    "    return start, end\n",
    "\n",
    "def _insert_at_end_of_section(md: str, header_text: str, block: str) -> str:\n",
    "    if not block.strip(): return md\n",
    "    start, end = _find_section_bounds(md, header_text)\n",
    "    if start is None:\n",
    "        return md.rstrip() + f\"\\n\\n## {header_text}\\n\\n{block.rstrip()}\\n\"\n",
    "    if block.strip() in md[start:end]:\n",
    "        return md\n",
    "    return md[:end] + (\"\\n\" if not md[start:end].endswith(\"\\n\") else \"\") + block.rstrip() + \"\\n\" + md[end:]\n",
    "\n",
    "def _ensure_toc_item(md: str, title: str) -> str:\n",
    "    start, end = _find_section_bounds(md, \"Table of Contents\")\n",
    "    if start is None:\n",
    "        md = md.rstrip() + \"\\n\\n## Table of Contents\\n\\n\"\n",
    "        start, end = _find_section_bounds(md, \"Table of Contents\")\n",
    "    anchor = title.strip().lower().replace(\" \", \"-\")\n",
    "    bullet = f\"- [{title}](#{anchor})\"\n",
    "    body = md[start:end]\n",
    "    if bullet in body: return md\n",
    "    new = body.rstrip() + (\"\\n\" if body and not body.endswith(\"\\n\") else \"\") + bullet + \"\\n\"\n",
    "    return md[:start] + new + md[end:]\n",
    "\n",
    "def _update_readme_merge(base_dir: Path, section_report_path: Path, plots):\n",
    "    readme = base_dir / \"README.md\"\n",
    "    md = readme.read_text(encoding=\"utf-8\") if readme.exists() else \"# Powercast — Project Overview\\n\\n## Table of Contents\\n\"\n",
    "    thumbs = []\n",
    "    for p in plots:\n",
    "        if p:\n",
    "            rel = Path(p).relative_to(base_dir).as_posix()\n",
    "            thumbs.append(f'<a href=\"./{rel}\"><img src=\"./{rel}\" width=\"260\" alt=\"Wk02_Section1 — {Path(p).name}\"></a>')\n",
    "    thumbs_block = \"\\n\".join(thumbs)\n",
    "    lst = \"### Wk02_Section1\\n\" + \"\\n\".join([f\"- [{Path(p).stem}](./{Path(p).relative_to(base_dir).as_posix()})\" for p in plots if p])\n",
    "    rel_rep = section_report_path.relative_to(base_dir).as_posix()\n",
    "    sec_block = f\"### Wk02_Section1\\n- [Week 2 – Section 1: Time-Based Feature Engineering](./{rel_rep})\"\n",
    "    wk2 = base_dir / WEEK_REPORT_FILENAME\n",
    "    if wk2.exists():\n",
    "        md = _ensure_toc_item(md, \"Top-level Week 2 Report\")\n",
    "        if \"## Top-level Week 2 Report\" not in md:\n",
    "            md += f\"\\n## Top-level Week 2 Report\\n\\n- [SDS-CP036-powercast_Wk02_Report_Business.md](./{wk2.relative_to(base_dir).as_posix()})\\n\"\n",
    "    md = _insert_at_end_of_section(md, \"Quick Gallery (click any thumbnail)\", thumbs_block)\n",
    "    md = _insert_at_end_of_section(md, \"Plots (grouped by Section)\", lst)\n",
    "    md = _insert_at_end_of_section(md, \"Section Reports (grouped)\", sec_block)\n",
    "    readme.write_text(md, encoding=\"utf-8\")\n",
    "    return str(readme)\n",
    "\n",
    "def process(base_dir: Path, input_csv: str|None):\n",
    "    base_dir = Path(base_dir)\n",
    "    out_dir, features_dir, plots_dir, reports_dir = _setup_dirs(base_dir)\n",
    "    _clean_prev(features_dir, plots_dir, reports_dir)\n",
    "\n",
    "    csv_path = _resolve_input_csv(base_dir, input_csv)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    dt_col = _find_datetime_column(df)\n",
    "    if dt_col is None: raise ValueError(\"No datetime-like timestamp column found.\")\n",
    "    dt = _ensure_dt(df, dt_col)\n",
    "\n",
    "    features = _engineer_time_features(dt)\n",
    "    feats_csv = features_dir/\"engineered_time_features.csv\"\n",
    "    features.to_csv(feats_csv, index=False)\n",
    "\n",
    "    deltas = dt.diff().dropna().dt.total_seconds().round()\n",
    "    diagnostics = {\"rows\": int(len(df)), \"start\": str(dt.min()), \"end\": str(dt.max())}\n",
    "    if len(deltas):\n",
    "        m = pd.Series(deltas).mode()\n",
    "        if len(m): diagnostics[\"inferred_frequency\"] = f\"{int(m.iloc[0])} seconds\"\n",
    "\n",
    "    hourly_png, dow_png = _plot_profiles(df, dt_col, plots_dir)\n",
    "\n",
    "    section_report = _write_section_report(reports_dir, features_dir, csv_path.name, diagnostics, [hourly_png, dow_png])\n",
    "    (out_dir/\"summary.json\").write_text(json.dumps({\"input_csv\": csv_path.name, \"datetime_column\": dt_col, **diagnostics}, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    s1 = {\"input_csv\": csv_path.name, \"plots\": [str(p) for p in [hourly_png, dow_png] if p], \"diagnostics\": diagnostics}\n",
    "    week_report = _render_week_report(base_dir, s1)\n",
    "    _update_readme_merge(base_dir, section_report, [p for p in [hourly_png, dow_png] if p])\n",
    "\n",
    "    return {\"features_csv\": str(feats_csv), \"section_report\": str(section_report), \"week_report\": week_report}\n",
    "\n",
    "# --- execute ---\n",
    "BASE = find_base_dir(Path.cwd())\n",
    "print(json.dumps(process(BASE, None), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68515662-c34f-4739-b6a9-3aac340a742e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
