{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Make_Requirements.py — derive requirements.txt from project notebooks.\n",
    "\n",
    "It scans for notebooks named like:\n",
    "  - GirishK_PwrCst_Wk1_Section1-Business*.ipynb    (requested pattern)\n",
    "  - GirishK_PwrCst_Wk1_Section*-Business*.ipynb    (convenience to capture Sections 1–N)\n",
    "\n",
    "It extracts `import x` and `from x import y` statements from code cells, maps\n",
    "module names to pip package names, and writes requirements.txt in the project\n",
    "base directory.\n",
    "\n",
    "Usage (CLI):\n",
    "  python Make_Requirements.py\n",
    "  python Make_Requirements.py --pinned                 # pin versions if available\n",
    "  python Make_Requirements.py --include-notebooks=no   # skip adding jupyter deps\n",
    "  python Make_Requirements.py --patterns \"GirishK_PwrCst_Wk1_Section1-Business*.ipynb,more*.ipynb\"\n",
    "  python Make_Requirements.py --out requirements.txt\n",
    "\n",
    "Usage (Notebook):\n",
    "  %run Make_Requirements.py --pinned\n",
    "  # or programmatic\n",
    "  from Make_Requirements import derive_requirements\n",
    "  derive_requirements(pinned=True)\n",
    "\n",
    "Notes:\n",
    "- Unknown args (like `-f kernel.json`) are tolerated and ignored.\n",
    "- Standard library modules are filtered out.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# -------- Project root detection --------\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    p = start.resolve()\n",
    "    for _ in range(12):\n",
    "        if (p / \".git\").exists() or (p / \"results\").exists() or (p / \"data\").exists():\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            break\n",
    "        p = p.parent\n",
    "    return start.resolve()\n",
    "\n",
    "# -------- Import parsing --------\n",
    "IMPORT_RE = re.compile(r'^\\s*import\\s+([A-Za-z_]\\w*(?:\\.[A-Za-z_]\\w*)?(?:\\s*,\\s*[A-Za-z_]\\w*(?:\\.[A-Za-z_]\\w*)?)*)', re.M)\n",
    "FROM_RE   = re.compile(r'^\\s*from\\s+([A-Za-z_]\\w*(?:\\.[A-Za-z_]\\w*)*)\\s+import\\s+', re.M)\n",
    "\n",
    "# Common module->pip renames\n",
    "MODULE_TO_PIP = {\n",
    "    \"sklearn\": \"scikit-learn\",\n",
    "    \"cv2\": \"opencv-python\",\n",
    "    \"PIL\": \"Pillow\",\n",
    "    \"bs4\": \"beautifulsoup4\",\n",
    "    \"yaml\": \"PyYAML\",\n",
    "    \"jinja2\": \"Jinja2\",\n",
    "    # identity for common libs\n",
    "    \"numpy\": \"numpy\",\n",
    "    \"pandas\": \"pandas\",\n",
    "    \"matplotlib\": \"matplotlib\",\n",
    "    \"seaborn\": \"seaborn\",\n",
    "    \"scipy\": \"scipy\",\n",
    "    \"statsmodels\": \"statsmodels\",\n",
    "    \"xgboost\": \"xgboost\",\n",
    "    \"lightgbm\": \"lightgbm\",\n",
    "    \"catboost\": \"catboost\",\n",
    "    \"plotly\": \"plotly\",\n",
    "    \"altair\": \"altair\",\n",
    "    \"requests\": \"requests\",\n",
    "    \"tqdm\": \"tqdm\",\n",
    "    \"numba\": \"numba\",\n",
    "    \"torch\": \"torch\",\n",
    "    \"tensorflow\": \"tensorflow\",\n",
    "}\n",
    "\n",
    "NOTEBOOK_DEPS = [\"jupyterlab\", \"ipykernel\"]\n",
    "\n",
    "def top_level(mod: str) -> str:\n",
    "    return mod.split(\".\")[0]\n",
    "\n",
    "def parse_imports_from_source(src: str) -> set[str]:\n",
    "    mods = set()\n",
    "    for m in IMPORT_RE.finditer(src):\n",
    "        group = m.group(1)\n",
    "        # handle \"import a, b.c, d as e\" by splitting on commas and spaces\n",
    "        for part in re.split(r\"\\s*,\\s*\", group):\n",
    "            # strip \" as alias\"\n",
    "            part = re.sub(r\"\\s+as\\s+\\w+$\", \"\", part.strip())\n",
    "            if part:\n",
    "                mods.add(top_level(part))\n",
    "    for m in FROM_RE.finditer(src):\n",
    "        mods.add(top_level(m.group(1)))\n",
    "    return mods\n",
    "\n",
    "def parse_notebook(path: Path) -> set[str]:\n",
    "    try:\n",
    "        nb = json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return set()\n",
    "    found = set()\n",
    "    for cell in nb.get(\"cells\", []):\n",
    "        if cell.get(\"cell_type\") != \"code\":\n",
    "            continue\n",
    "        src = \"\".join(cell.get(\"source\", []))\n",
    "        found |= parse_imports_from_source(src)\n",
    "    return found\n",
    "\n",
    "# -------- Resolution & writing --------\n",
    "def stdlib_names() -> set[str]:\n",
    "    import sys\n",
    "    names = set(getattr(sys, \"stdlib_module_names\", set()))\n",
    "    # Add a few that may be missing or aliased in some environments\n",
    "    names |= {\"pathlib\", \"re\", \"json\", \"os\", \"sys\", \"datetime\", \"itertools\", \"collections\", \"math\", \"random\", \"typing\"}\n",
    "    return names\n",
    "\n",
    "def module_to_pip(mod: str) -> str | None:\n",
    "    if mod in MODULE_TO_PIP:\n",
    "        return MODULE_TO_PIP[mod]\n",
    "    # If it's clearly stdlib, ignore\n",
    "    if mod in stdlib_names():\n",
    "        return None\n",
    "    # default: assume same name is the pip package\n",
    "    return mod\n",
    "\n",
    "def get_version(pkg: str) -> str | None:\n",
    "    try:\n",
    "        mod = __import__(pkg if pkg != \"scikit-learn\" else \"sklearn\")\n",
    "        v = getattr(mod, \"__version__\", None)\n",
    "        if v is None and pkg == \"matplotlib\":\n",
    "            import matplotlib\n",
    "            v = matplotlib.__version__\n",
    "        return v\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def derive_requirements(\n",
    "    pinned: bool = False,\n",
    "    include_notebooks: bool = True,\n",
    "    patterns: list[str] | None = None,\n",
    "    out: str | Path = \"requirements.txt\",\n",
    "    start_dir: Path | None = None,\n",
    ") -> Path:\n",
    "    patterns = patterns or [\n",
    "        \"GirishK_PwrCst_Wk1_Section1-Business*.ipynb\",\n",
    "        \"GirishK_PwrCst_Wk1_Section*-Business*.ipynb\",\n",
    "    ]\n",
    "    root = find_project_root(start_dir or Path.cwd())\n",
    "    nb_paths: list[Path] = []\n",
    "    for pat in patterns:\n",
    "        nb_paths.extend(root.rglob(pat))\n",
    "\n",
    "    imports: set[str] = set()\n",
    "    for nbp in sorted(set(nb_paths)):\n",
    "        imports |= parse_notebook(nbp)\n",
    "\n",
    "    # Map to pip names, drop stdlib/unknowns\n",
    "    pkgs: set[str] = set()\n",
    "    for mod in sorted(imports):\n",
    "        pip_name = module_to_pip(mod)\n",
    "        if pip_name:\n",
    "            pkgs.add(pip_name)\n",
    "\n",
    "    if include_notebooks:\n",
    "        pkgs |= set(NOTEBOOK_DEPS)\n",
    "\n",
    "    lines = [\"# Auto-derived by Make_Requirements.py\",\n",
    "             f\"# Generated: {datetime.now():%Y-%m-%d %H:%M:%S}\",\n",
    "             f\"# Scanned patterns: {', '.join(patterns)}\",\n",
    "             \"\"]\n",
    "    for pkg in sorted(pkgs):\n",
    "        if pinned:\n",
    "            ver = get_version(pkg)\n",
    "            if ver:\n",
    "                lines.append(f\"{pkg}=={ver}\")\n",
    "            else:\n",
    "                lines.append(pkg)  # fallback if version unknown\n",
    "        else:\n",
    "            lines.append(pkg)\n",
    "\n",
    "    out_path = (root / out).resolve()\n",
    "    out_path.write_text(\"\\n\".join(lines).strip() + \"\\n\", encoding=\"utf-8\")\n",
    "    return out_path\n",
    "\n",
    "def main(argv: list[str] | None = None):\n",
    "    ap = argparse.ArgumentParser(add_help=True, allow_abbrev=False)\n",
    "    ap.add_argument(\"--pinned\", action=\"store_true\", help=\"Pin versions if importable\")\n",
    "    ap.add_argument(\"--include-notebooks\", choices=[\"yes\",\"no\"], default=\"yes\",\n",
    "                    help=\"Include jupyter deps (jupyterlab, ipykernel) [default: yes]\")\n",
    "    ap.add_argument(\"--patterns\", type=str, default=\"GirishK_PwrCst_Wk1_Section1-Business*.ipynb,GirishK_PwrCst_Wk1_Section*-Business*.ipynb\",\n",
    "                    help=\"Comma-separated glob patterns to scan\")\n",
    "    ap.add_argument(\"--out\", type=str, default=\"requirements.txt\", help=\"Output filename relative to project root\")\n",
    "\n",
    "    # Tolerate unknown ipykernel args\n",
    "    args, unknown = ap.parse_known_args(argv)\n",
    "\n",
    "    pats = [p.strip() for p in args.patterns.split(\",\") if p.strip()]\n",
    "    include_nb = (args.include_notebooks.lower() == \"yes\")\n",
    "\n",
    "    path = derive_requirements(\n",
    "        pinned=args.pinned,\n",
    "        include_notebooks=include_nb,\n",
    "        patterns=pats,\n",
    "        out=args.out,\n",
    "        start_dir=Path.cwd(),\n",
    "    )\n",
    "    print(f\"Wrote {path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}