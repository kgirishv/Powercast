{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e387ce0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T03:37:38.561542Z",
     "iopub.status.busy": "2025-08-18T03:37:38.561118Z",
     "iopub.status.idle": "2025-08-18T03:37:38.589325Z",
     "shell.execute_reply": "2025-08-18T03:37:38.588861Z",
     "shell.execute_reply.started": "2025-08-18T03:37:38.561522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README regenerated at: /home/6376f5a9-d12b-4255-9426-c0091ad440a7/Powercast/README.md\n"
     ]
    }
   ],
   "source": [
    "# Refresh README.md (Week1 & Week2 Sections 1..5)\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "TITLES = {\n",
    "    # Week 2\n",
    "    \"Wk02_Section1\": \"Time-Based Feature Engineering\",\n",
    "    \"Wk02_Section2\": \"Lags & Rolling Statistics\",\n",
    "    \"Wk02_Section3\": \"Feature Scaling & Normalization\",\n",
    "    \"Wk02_Section4\": \"Data Splitting & Preparation\",\n",
    "    \"Wk02_Section5\": \"Data Quality & Preprocessing\",\n",
    "    # Week 1 (update if you have exact titles)\n",
    "    \"Wk01_Section1\": \"Time Checks & Overview\",\n",
    "    \"Wk01_Section2\": \"Week 1 â€” Section 2\",\n",
    "    \"Wk01_Section3\": \"Week 1 â€” Section 3\",\n",
    "    \"Wk01_Section4\": \"Week 1 â€” Section 4\",\n",
    "    \"Wk01_Section5\": \"Week 1 â€” Section 5\",\n",
    "}\n",
    "\n",
    "def find_base_dir(start: Path) -> Path:\n",
    "    p = start.resolve()\n",
    "    for _ in range(8):\n",
    "        if (p/\"Code\").exists() and ((p/\"results\").exists() or (p/\"data\").exists()):\n",
    "            return p\n",
    "        if p.name.lower()==\"powercast\" and (p/\"Code\").exists():\n",
    "            return p\n",
    "        p = p.parent\n",
    "    return start.resolve()\n",
    "\n",
    "def collect_sections(results_dir: Path, week_prefix: str, repo_prefix: str) -> list[str]:\n",
    "    blocks = []\n",
    "    for sec in range(1, 6):\n",
    "        sec_key = f\"{week_prefix}_Section{sec}\"\n",
    "        sec_dir = results_dir / sec_key\n",
    "        if not sec_dir.exists(): \n",
    "            continue\n",
    "\n",
    "        plots_dir = sec_dir / \"plots\"\n",
    "        reports_dir = sec_dir / \"reports\"\n",
    "        title = TITLES.get(sec_key, sec_key)\n",
    "\n",
    "        lines = [f\"### {sec_key} â€” {title}\"]\n",
    "\n",
    "        if plots_dir.exists():\n",
    "            for png in sorted(plots_dir.glob(\"*.png\")):\n",
    "                rel = f\"{repo_prefix}results/{sec_key}/plots/{png.name}\"\n",
    "                friendly = png.stem.replace(\"_\", \" \").title()\n",
    "                lines.append(f\"- ðŸ“Š [{friendly}]({rel})\")\n",
    "\n",
    "        if reports_dir.exists():\n",
    "            report = reports_dir / f\"SDS-CP036-powercast_{sec_key}_Business_Report.md\"\n",
    "            if report.exists():\n",
    "                rel = f\"{repo_prefix}results/{sec_key}/reports/{report.name}\"\n",
    "                lines.append(f\"- ðŸ’¼ [Business Report]({rel})\")\n",
    "\n",
    "        blocks.append(\"\\n\".join(lines))\n",
    "    return blocks\n",
    "\n",
    "def build_readme(base: Path, repo_prefix: str=\"./\") -> Path:\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    results = base / \"results\"\n",
    "\n",
    "    wk2_blocks = collect_sections(results, \"Wk02\", repo_prefix)\n",
    "    wk1_blocks = collect_sections(results, \"Wk01\", repo_prefix)\n",
    "\n",
    "    consolidated = []\n",
    "    wk2 = base / \"SDS-CP036-powercast_Wk02_Report_Business.md\"\n",
    "    if wk2.exists():\n",
    "        consolidated.append(f\"- ðŸ“˜ [Week 2 Consolidated Business Report]({repo_prefix}{wk2.name})\")\n",
    "    wk1 = base / \"SDS-CP036-powercast_Wk01_Report_Business.md\"\n",
    "    if wk1.exists():\n",
    "        consolidated.append(f\"- ðŸ“˜ [Week 1 Consolidated Business Report]({repo_prefix}{wk1.name})\")\n",
    "\n",
    "    lines = [\n",
    "        \"# SDS-CP036-powercast â€” Results Overview\",\n",
    "        \"\",\n",
    "        f\"ðŸ“… **Generated:** {ts}\",\n",
    "        \"\",\n",
    "        \"---\",\n",
    "        \"\",\n",
    "        \"## Week 2 â€” Section Reports\",\n",
    "        \"\",\n",
    "        *(wk2_blocks if wk2_blocks else [\"_No Week 2 outputs found._\"]),\n",
    "        \"\",\n",
    "        \"---\",\n",
    "        \"\",\n",
    "        \"## Week 1 â€” Section Reports\",\n",
    "        \"\",\n",
    "        *(wk1_blocks if wk1_blocks else [\"_No Week 1 outputs found._\"]),\n",
    "        \"\",\n",
    "        \"---\",\n",
    "        \"\",\n",
    "        \"## Consolidated Reports\",\n",
    "        \"\",\n",
    "        *(consolidated if consolidated else [\"_No consolidated reports present._\"]),\n",
    "        \"\",\n",
    "    ]\n",
    "\n",
    "    out = base / \"README.md\"\n",
    "    out.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "    return out\n",
    "\n",
    "# ---- Execute with local relative links by default ----\n",
    "BASE = find_base_dir(Path.cwd())\n",
    "path = build_readme(BASE, repo_prefix=\"./\")\n",
    "print(f\"README regenerated at: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c31c20-9717-4ef3-bf9f-649bcb977db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
