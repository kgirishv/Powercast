{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f456b843-360b-4759-8bee-376548b0e0ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T21:50:22.095471Z",
     "iopub.status.busy": "2025-08-09T21:50:22.095268Z",
     "iopub.status.idle": "2025-08-09T21:50:26.183187Z",
     "shell.execute_reply": "2025-08-09T21:50:26.182672Z",
     "shell.execute_reply.started": "2025-08-09T21:50:22.095455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Section 5 (Business) complete.\n",
      "- Loaded cleaned CSV from: /home/6376f5a9-d12b-4255-9426-c0091ad440a7/SDS-CP036-powercast/results/Wk01_Section4/cleaned_power_weather_final.csv\n",
      "- Saved cleaned CSV to:   /home/6376f5a9-d12b-4255-9426-c0091ad440a7/SDS-CP036-powercast/results/Wk01_Section4/cleaned_power_weather_final.csv\n",
      "- Also copied to:         /home/6376f5a9-d12b-4255-9426-c0091ad440a7/SDS-CP036-powercast/results/Wk01_Section5/cleaned_power_weather_final.csv\n",
      "- Plots in:               /home/6376f5a9-d12b-4255-9426-c0091ad440a7/SDS-CP036-powercast/results/Wk01_Section5/plots\n",
      "- Report:                 /home/6376f5a9-d12b-4255-9426-c0091ad440a7/SDS-CP036-powercast/results/Wk01_Section5/SDS-CP036-powercast_Wk01_Section5_Report_Business.md\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# section5_business.py\n",
    "# Week 1 – Section 5 (Business): Data Quality & Sensor Anomalies\n",
    "# Outputs under results/Wk01_Section5:\n",
    "#  - plots/*.png (before/after hist & boxplots)\n",
    "#  - SDS-CP036-powercast_Wk01_Section5_Report_Business.md\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --------------------------\n",
    "# 0) Paths & helpers\n",
    "# --------------------------\n",
    "BASE_PROJECT_NAME = \"SDS-CP036-powercast\"\n",
    "RUN_TAG = \"Wk01_Section5\"\n",
    "\n",
    "def locate_project_root(start: Path, marker: str = BASE_PROJECT_NAME, max_up: int = 8) -> Path:\n",
    "    p = start.resolve()\n",
    "    for _ in range(max_up + 1):\n",
    "        if p.name == marker or marker in p.parts:\n",
    "            return p if p.name == marker else Path(*p.parts[:p.parts.index(marker)+1])\n",
    "        p = p.parent\n",
    "    return start.resolve()\n",
    "\n",
    "CWD = Path.cwd()\n",
    "BASE_DIR = locate_project_root(CWD, BASE_PROJECT_NAME)\n",
    "RESULTS_DIR = BASE_DIR / \"results\" / RUN_TAG\n",
    "PLOTS_DIR = RESULTS_DIR / \"plots\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Where Section 4 likely saved things\n",
    "SEC4_DIR = BASE_DIR / \"results\" / \"Wk01_Section4\"\n",
    "\n",
    "# Candidate filenames Section 4 might have used\n",
    "SEC4_CANDIDATES = [\n",
    "    SEC4_DIR / \"cleaned_power_weather_final.csv\",\n",
    "    SEC4_DIR / f\"{BASE_PROJECT_NAME}_Wk01_Section4_cleaned_power_weather_final.csv\",\n",
    "]\n",
    "\n",
    "def find_cleaned_csv() -> Path:\n",
    "    # 1) Direct candidates\n",
    "    for p in SEC4_CANDIDATES:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    # 2) Anything under Section 4 folder matching pattern\n",
    "    if SEC4_DIR.exists():\n",
    "        hits = sorted(SEC4_DIR.rglob(\"*cleaned_power_weather_final.csv\"))\n",
    "        if hits:\n",
    "            return hits[0]\n",
    "    # 3) Last resort: search entire results tree\n",
    "    hits = sorted((BASE_DIR / \"results\").rglob(\"*cleaned_power_weather_final.csv\"))\n",
    "    if hits:\n",
    "        return hits[0]\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find 'cleaned_power_weather_final.csv'. \"\n",
    "        \"Please run Section 4 script first to generate it.\"\n",
    "    )\n",
    "\n",
    "# --------------------------\n",
    "# 1) Load data\n",
    "# --------------------------\n",
    "CLEANED_PREV = find_cleaned_csv()\n",
    "df = pd.read_csv(CLEANED_PREV, parse_dates=[\"DateTime\"])\n",
    "\n",
    "# Keep numeric columns of interest\n",
    "energy_cols = [\"Global_active_power\",\"Global_reactive_power\",\"Voltage\",\n",
    "               \"Global_intensity\",\"Sub_metering_1\",\"Sub_metering_2\",\"Sub_metering_3\"]\n",
    "weather_cols = [\"temperature_2m\",\"relative_humidity_2m\",\"wind_speed_10m\",\"shortwave_radiation\"]\n",
    "\n",
    "# Only keep columns that exist (be tolerant)\n",
    "keep_cols = [\"DateTime\"] + [c for c in energy_cols + weather_cols if c in df.columns]\n",
    "df = df[keep_cols].copy()\n",
    "\n",
    "# Coerce numerics\n",
    "for c in keep_cols:\n",
    "    if c != \"DateTime\":\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# --------------------------\n",
    "# 2) Quick quality checks\n",
    "# --------------------------\n",
    "# Missing counts\n",
    "missing_before = df.isna().sum().to_dict()\n",
    "\n",
    "# Negative checks for Sub_metering_* (should be >=0)\n",
    "negatives = {}\n",
    "for z in [\"Sub_metering_1\",\"Sub_metering_2\",\"Sub_metering_3\"]:\n",
    "    if z in df.columns:\n",
    "        negatives[z] = int((df[z] < 0).sum())\n",
    "\n",
    "# --------------------------\n",
    "# 3) Plots - BEFORE cleaning\n",
    "# --------------------------\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Histograms (before)\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_before = df.drop(columns=[\"DateTime\"]).select_dtypes(include=[float, int])\n",
    "numeric_before.hist(bins=50, figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "PLOT_BEFORE_HIST = PLOTS_DIR / f\"{BASE_PROJECT_NAME}_{RUN_TAG}_Plot_Hist_Before.png\"\n",
    "plt.savefig(PLOT_BEFORE_HIST, dpi=130)\n",
    "plt.close()\n",
    "\n",
    "# Boxplots (before)\n",
    "plt.figure(figsize=(12, 6))\n",
    "m_before = numeric_before.melt(var_name=\"Feature\", value_name=\"Value\")\n",
    "sns.boxplot(data=m_before, x=\"Feature\", y=\"Value\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "PLOT_BEFORE_BOX = PLOTS_DIR / f\"{BASE_PROJECT_NAME}_{RUN_TAG}_Plot_Box_Before.png\"\n",
    "plt.savefig(PLOT_BEFORE_BOX, dpi=130)\n",
    "plt.close()\n",
    "\n",
    "# --------------------------\n",
    "# 4) Clean: fix negatives, cap/clip outliers, simple impute\n",
    "# --------------------------\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Negatives -> NA for sub meterings\n",
    "for z in [\"Sub_metering_1\",\"Sub_metering_2\",\"Sub_metering_3\"]:\n",
    "    if z in df_clean.columns:\n",
    "        df_clean.loc[df_clean[z] < 0, z] = np.nan\n",
    "\n",
    "# IQR clipping for each numeric column (robust)\n",
    "def iqr_clip(s: pd.Series, k: float = 1.5) -> pd.Series:\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    low, high = q1 - k*iqr, q3 + k*iqr\n",
    "    return s.clip(lower=low, upper=high)\n",
    "\n",
    "for c in df_clean.columns:\n",
    "    if c != \"DateTime\" and pd.api.types.is_numeric_dtype(df_clean[c]):\n",
    "        df_clean[c] = iqr_clip(df_clean[c])\n",
    "\n",
    "# Simple forward-fill then back-fill for small gaps\n",
    "df_clean = df_clean.sort_values(\"DateTime\").reset_index(drop=True)\n",
    "df_clean.update(df_clean.select_dtypes(include=[float, int]).ffill().bfill())\n",
    "\n",
    "# Missing counts after\n",
    "missing_after = df_clean.isna().sum().to_dict()\n",
    "\n",
    "# --------------------------\n",
    "# 5) Plots - AFTER cleaning\n",
    "# --------------------------\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_after = df_clean.drop(columns=[\"DateTime\"]).select_dtypes(include=[float, int])\n",
    "numeric_after.hist(bins=50, figsize=(12, 8))\n",
    "plt.tight_layout()\n",
    "PLOT_AFTER_HIST = PLOTS_DIR / f\"{BASE_PROJECT_NAME}_{RUN_TAG}_Plot_Hist_After.png\"\n",
    "plt.savefig(PLOT_AFTER_HIST, dpi=130)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "m_after = numeric_after.melt(var_name=\"Feature\", value_name=\"Value\")\n",
    "sns.boxplot(data=m_after, x=\"Feature\", y=\"Value\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "PLOT_AFTER_BOX = PLOTS_DIR / f\"{BASE_PROJECT_NAME}_{RUN_TAG}_Plot_Box_After.png\"\n",
    "plt.savefig(PLOT_AFTER_BOX, dpi=130)\n",
    "plt.close()\n",
    "\n",
    "# --------------------------\n",
    "# 6) Save cleaned dataset (do not multiply names)\n",
    "# --------------------------\n",
    "final_clean_csv = BASE_DIR / \"results\" / \"Wk01_Section4\" / \"cleaned_power_weather_final.csv\"\n",
    "# Also mirror to Wk01_Section5 for convenience\n",
    "final_clean_csv_5 = RESULTS_DIR / \"cleaned_power_weather_final.csv\"\n",
    "\n",
    "df_clean.to_csv(final_clean_csv, index=False)\n",
    "df_clean.to_csv(final_clean_csv_5, index=False)\n",
    "\n",
    "# --------------------------\n",
    "# 7) Business Markdown (Q1–Q3)\n",
    "# --------------------------\n",
    "def fmt_missing(d: dict) -> str:\n",
    "    lines = []\n",
    "    for k, v in sorted(d.items()):\n",
    "        if k == \"DateTime\": \n",
    "            continue\n",
    "        lines.append(f\"- {k}: {v}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "md_path = RESULTS_DIR / f\"{BASE_PROJECT_NAME}_Wk01_Section5_Report_Business.md\"\n",
    "\n",
    "md = []\n",
    "md.append(f\"# {BASE_PROJECT_NAME} – Wk01_Section5 – Data Quality & Sensor Anomalies (Business Report)\\n\")\n",
    "md.append(\"## Key Questions Answered\\n\")\n",
    "\n",
    "md.append(\"**Q1: Did I detect any outliers in the weather or consumption readings?**  \\n\"\n",
    "          \"Yes. I found outliers across several features using boxplots/IQR rules and histograms. \"\n",
    "          \"Sub-meter readings occasionally had extreme spikes, and weather features showed sporadic high/low values.\\n\")\n",
    "\n",
    "md.append(\"**Q2: How did I identify and treat these anomalies?**  \\n\"\n",
    "          \"I used IQR-based clipping (to cap extreme values) and replaced negative sub-meter readings with blanks (then filled small gaps). \"\n",
    "          \"I also forward-/back-filled short missing stretches.\\n\")\n",
    "\n",
    "md.append(\"**Q3: What might be the impact of retaining or removing them in my model?**  \\n\"\n",
    "          \"Capping/removing extremes reduces noise and helps models generalize, while retaining them can cause unstable forecasts. \"\n",
    "          \"For production systems, I would keep this cleaning to improve reliability.\\n\")\n",
    "\n",
    "md.append(\"## Missing Values (Before Cleaning)\\n\")\n",
    "md.append(fmt_missing(missing_before) + \"\\n\")\n",
    "\n",
    "md.append(\"## Missing Values (After Cleaning)\\n\")\n",
    "md.append(fmt_missing(missing_after) + \"\\n\")\n",
    "\n",
    "md.append(\"## Visual Evidence\\n\")\n",
    "md.append(f\"**Before – Histograms**  \\n![]({PLOT_BEFORE_HIST.relative_to(RESULTS_DIR).as_posix()})\\n\")\n",
    "md.append(f\"**Before – Boxplots**  \\n![]({PLOT_BEFORE_BOX.relative_to(RESULTS_DIR).as_posix()})\\n\")\n",
    "md.append(f\"**After – Histograms**  \\n![]({PLOT_AFTER_HIST.relative_to(RESULTS_DIR).as_posix()})\\n\")\n",
    "md.append(f\"**After – Boxplots**  \\n![]({PLOT_AFTER_BOX.relative_to(RESULTS_DIR).as_posix()})\\n\")\n",
    "\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(md))\n",
    "\n",
    "print(\"✅ Section 5 (Business) complete.\")\n",
    "print(f\"- Loaded cleaned CSV from: {CLEANED_PREV}\")\n",
    "print(f\"- Saved cleaned CSV to:   {final_clean_csv}\")\n",
    "print(f\"- Also copied to:         {final_clean_csv_5}\")\n",
    "print(f\"- Plots in:               {PLOTS_DIR}\")\n",
    "print(f\"- Report:                 {md_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b11fa9-6a5d-431a-b589-714d5f4bb26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
